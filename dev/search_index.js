var documenterSearchIndex = {"docs":
[{"location":"4_quantum_trajectories/#Quantum-trajectories","page":"Quantum Trajectories","title":"Quantum trajectories","text":"","category":"section"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"Claim: you should not use master equation solvers. You don't pay the exponential cost when working with classical probability distributions, instead we use Monte Carlo simulations. How can we do the same with quantum systems?","category":"page"},{"location":"4_quantum_trajectories/#Good-resources","page":"Quantum Trajectories","title":"Good resources","text":"","category":"section"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"QuantumOptics documentation","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"QuTiP documentation","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"Mølmer, Castin, and Dalibard","category":"page"},{"location":"4_quantum_trajectories/#Monte-Carlo-wavefunction-in-QuantumOptics.jl","page":"Quantum Trajectories","title":"Monte Carlo wavefunction in QuantumOptics.jl","text":"","category":"section"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"using QuantumOptics\n\ncutoff = 32\nB = FockBasis(cutoff)\na = destroy(B)\nω = 1.0\nH = ω*a'*a\n\nγ = 0.1\nL = [√γ*a]\n\nψ = fockstate(B, 18)\n\nts = 0:0.01:3*2*π\n\n_, ρs = timeevolution.master(ts,ψ,H,L)\n\n_, ψs = timeevolution.mcwf(ts,ψ,H,L)\nnothing #hide","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"using CairoMakie\nfig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\n\nlines!(ax,ts,real.(expect.((a'*a,),ρs)))\nlines!(ax,ts,real.(expect.((a'*a,),ψs)))\n\nfig","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"Is the environment photon counting or doing homodyne readout?","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"We can make lots of trajectories and average them...","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"fig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\n\n_, ρs = timeevolution.master(ts,ψ,H,L)\n\nlines!(ax,ts,real.(expect.((a'*a,),ρs)))\n\ntrajectories = []\nn_traj = 100\n\nfor _ in 1:n_traj \n    _, ψs = timeevolution.mcwf(ts,ψ,H,L)\n    push!(trajectories,ψs)\n    lines!(ax,ts,real.(expect.((a'*a,),ψs)), color = (:gray,0.1))\nend\n\nsols_avg = sum([dm.(ψs) for ψs in trajectories])/n_traj\nlines!(ax,ts, real.(expect.((a'*a,), sols_avg)))\n\nfig","category":"page"},{"location":"4_quantum_trajectories/#Cat-states","page":"Quantum Trajectories","title":"Cat states","text":"","category":"section"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"α = 4.0\n\nl0 = (coherentstate(B,α) + coherentstate(B,-α)) / √2\nl1 = (coherentstate(B,1im*α) + coherentstate(B,-1im*α)) / √2\n\nmix0 = (dm(coherentstate(B,α)) + dm(coherentstate(B,-α))) / 2\nmix1 = (dm(coherentstate(B,1im*α)) + dm(coherentstate(B,-1im*α))) / 2\nnothing #hide\n#TODO: make 4 panel Wigner function plot","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"H = ω*a'*a\nts = 0:0.01:π/2\n\n_, ψs = timeevolution.schroedinger(ts,l0,H)\n\nlines(ts, real.(expect.((projector(l0),), ψs)))\nlines!(ts, real.(expect.((projector(l1),), ψs)))\ncurrent_figure()","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"We can think of this as a logical gate, it exchanges our two states. ","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"We can add loss:","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"γ = 0.01\nL = [√γ*a]\n_,ρs = timeevolution.master(ts,l0,H,L);\nlines!(ts, real.(expect.((projector(l0),),ρs)), linestyle=:dash)\nlines!(ts, real.(expect.((projector(l1),),ρs)), linestyle=:dash)\ncurrent_figure()","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"We can use non Hermitian time evolution as a worst case analysis. ","category":"page"},{"location":"4_quantum_trajectories/","page":"Quantum Trajectories","title":"Quantum Trajectories","text":"Hnotherm = H - im/1 *L[1]'*L[1]\n_,ψnhs = timeevolution.schroedinger(ts,l0,Hnotherm);\nlines!(ts, real.(expect.((projector(l0),),ψnhs)), linestyle=:dot)\nlines!(ts, real.(expect.((projector(l1),),ψnhs)), linestyle=:dot)\ncurrent_figure()","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Dynamics-and-QuantumOptics.jl-Stefan-Krastanov","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl - Stefan Krastanov","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"This package should be thought of as a domain specific linear algebra wrapper.","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Operator-basics","page":"Dynamics and QuantumOptics.jl","title":"Operator basics","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using QuantumOpticsBase\n\ncutoff = 25\n\nF = FockBasis(cutoff)\n\nΨ = fockstate(F,5)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"S = SpinBasis(1//2)\ns = spindown(S)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"G = GenericBasis(100)\nbasisstate(G,2)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"C = F ⊗ S\n\nsparse(dm(Ψ⊗s))\n","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"projector(Ψ⊗s)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using BenchmarkTools\nP = projector(Ψ)\nPs = sparse(P)\n\n@benchmark P*Ψ","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"@benchmark Ps*Ψ","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"We can use in-place or mutating functions to improve performance. This is one of the first things to think about optimizing when looking for speedups.","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using LinearAlgebra: mul!\n\nbuffer = copy(Ψ)\n@benchmark mul!(buffer, Ps, Ψ)","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Composite-spaces","page":"Dynamics and QuantumOptics.jl","title":"Composite spaces","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"We can create composite spaces and operators with the '\\otimes' symbol representing the tensor product.","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"psi = fockstate(F,4)⊗spinup(S)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"create(F)⊗identityoperator(S)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"This does not scale well! We have a function called embed to address this problem","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"embed(F⊗S, 1, create(F))","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"We can take a partial trace with ptrace()","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"l = spindown(S)\nh = spinup(S)\n\nbell = (l⊗l + h⊗h) / √2\n\nptrace(bell,2)","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Coherent-states","page":"Dynamics and QuantumOptics.jl","title":"Coherent states","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using QuantumOptics","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"QuantumOptics depends on DifferentialEquations, so has a much longer precompile time compared to QuantumOpticsBase, which defines the methods for working with quantum states and operators without any time evolution. ","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"We will work with the quantum harmonic oscillator and look at coherent states in phase space.","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"cutoff = 32\nB = FockBasis(cutoff)\nω = 1.0\na = destroy(B)\n\nH = ω*a'*a","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"Now we can make a coherent state","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"α = 4\nψ = coherentstate(B, α)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"a*ψ ≈ α*ψ","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"TODO: what is going wrong here?","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using CairoMakie\nquad = -10:0.1:10\n\nw = wigner(ψ,quad,quad)\n\nfig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\nheatmap!(quad,quad,w)\nfig","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Schrodinger-dynamics","page":"Dynamics and QuantumOptics.jl","title":"Schrodinger dynamics","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"ts = 0:0.1:3*2*π\n\n_, ψs = timeevolution.schroedinger(ts,ψ,H)\n\nnothing #hide","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"x = (a' + a)/√2\np = 1im*(a' - a)/√2\n\nfig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\nlines!(ax,ts,real.(expect.((x,),ψs)))\nlines!(ax,ts,real.(expect.((p,),ψs)))\nfig","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"lines(norm.(ψs))","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"First, the naive way to create a time-dependent Hamiltonian","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"function Hdynamic(t,psi)\n    return H+p*4*sin(8*ω*t)\nend\n\n_, ψs = timeevolution.schroedinger_dynamic(ts,ψ,Hdynamic)\n\nfig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\nlines!(ax,ts,real.(expect.((x,),ψs)))\nlines!(ax,ts,real.(expect.((p,),ψs)))\nfig","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"SciMLOperators has an interesting way to create time-dependent operators in an allocation-efficient way.","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using BenchmarkTools\nHlazy = H + TimeDependentSum(t-> 4*sin(8*ω*t),p)\n@benchmark _, ψs = timeevolution.schroedinger_dynamic(ts, ψ, Hlazy)","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"And the old way:","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"@benchmark _, ψs = timeevolution.schroedinger_dynamic(ts,ψ,Hdynamic)","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Trying-out-different-solvers","page":"Dynamics and QuantumOptics.jl","title":"Trying out different solvers","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"using OrdinaryDiffEqLowOrderRK: DP5\nusing OrdinaryDiffEqTsit5: Tsit5\nusing OrdinaryDiffEqVerner: Vern8","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"A good discussion on Schrodinger dynamics and solver tolerance","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"@benchmark _, ψs = timeevolution.schroedinger_dynamic(ts, ψ, Hlazy; alg =\nDP5())","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"@benchmark _, ψs = timeevolution.schroedinger_dynamic(ts, ψ, Hlazy; alg =\nTsit5())","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"@benchmark _, ψs = timeevolution.schroedinger_dynamic(ts, ψ, Hlazy; alg =\nVern8())","category":"page"},{"location":"3_dynamics_and_quantumoptics/#Master-equation-evolution","page":"Dynamics and QuantumOptics.jl","title":"Master equation evolution","text":"","category":"section"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"γ = 0.1\n_, ρs = timeevolution.master(ts,ψ,H,[√γ*a])\n\nfig = Figure()\nax = Axis(fig[1,1], aspect = DataAspect())\nlines!(ax,ts,real.(expect.((x,),ρs)))\nlines!(ax,ts,real.(expect.((p,),ρs)))\nfig","category":"page"},{"location":"3_dynamics_and_quantumoptics/","page":"Dynamics and QuantumOptics.jl","title":"Dynamics and QuantumOptics.jl","text":"TODO: Lindblad is nonlinear with respect to collapse operators? ","category":"page"},{"location":"5_optimization_methods/#Optimization-Methods-Lecture-1","page":"Optimization Methods","title":"Optimization Methods - Lecture 1","text":"","category":"section"},{"location":"5_optimization_methods/#Getting-started","page":"Optimization Methods","title":"Getting started","text":"","category":"section"},{"location":"5_optimization_methods/#Goals","page":"Optimization Methods","title":"Goals","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Gradient descent\nNewton's method\nRegularization\nNewton approximations\nLine search\nKKT conditions\nExercises with GRAPE","category":"page"},{"location":"5_optimization_methods/#Unconstrained-Optimization","page":"Optimization Methods","title":"Unconstrained Optimization","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"min_bm x J(bm x)","category":"page"},{"location":"5_optimization_methods/#Necessary-Conditions","page":"Optimization Methods","title":"Necessary Conditions","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"nabla J ( bmx^* ) = bm0","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"nabla^2 J(bmx^*) succeq bm0","category":"page"},{"location":"5_optimization_methods/#Gradient-Descent","page":"Optimization Methods","title":"Gradient Descent","text":"","category":"section"},{"location":"5_optimization_methods/#Gradient-Descent-Update-Rule","page":"Optimization Methods","title":"Gradient Descent Update Rule","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"The gradient descent algorithm updates the current point x by stepping in the direction opposite the gradient:","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"bmx_i+1 = bmx_i - eta cdot nabla J(bmx_i)","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"where eta is the learning rate - controlling the step size.","category":"page"},{"location":"5_optimization_methods/#Example-solve","page":"Optimization Methods","title":"Example solve","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"We're going to apply gradient descent to minimize the following:","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"h(x) = x^4 + x^3 - x^2 - x","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"This is a smooth, non-linear function with multiple stationary points. Our goal is to find a local minimum by starting from an initial value and following the gradient downhill: nabla h(x^*) = 0","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"using CairoMakie\n\nfunction h(x)\n    return x.^4 + x.^3 - x.^2 - x\nend\n\nfunction ∇h(x)\n    return 4.0*x.^3 + 3.0*x.^2 - 2.0*x - 1.0\nend\n\nx = range(-1.75,1.25,1000)\n\n# Initial guess\nx₀ = 1.19\n\nxᵢ = x₀\n\ngradient_descent_step(xᵢ; η=0.01) = xᵢ - η * ∇h(xᵢ)\n\n# Initial plot\nfig1 = Figure()\nax1 = Axis(fig1[1,1])\nlines!(ax1, x, h(x))\n\n# Perform gradient descent step\nxᵢ₊₁ = gradient_descent_step(xᵢ, η=0.01) \nplot!(ax1, [xᵢ], [h(xᵢ)], color=:orange, marker='x', markersize=25)\nxᵢ = xᵢ₊₁\nfig1","category":"page"},{"location":"5_optimization_methods/#Newton's-Method","page":"Optimization Methods","title":"Newton's Method","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Now we're using a local quadratic approximation, for a nearby guess x_k the value of J(bmx) can be well-approximated as","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"J(bmx) approx J(bmx_k) + nabla J(bmx)^T (bmx - bmx_k) + frac12 (bmx - bmx_k)^T nabla^2 J(bmx_k) (bmx - bmx_k)","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"And we can solve for our necessary condition","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"beginalign\nbm0  oversetmathrm= nabla J(bmx + Delta bmx) approx nabla J(bmx) + nabla^2 J(bmx) Delta bmx \nDelta bmx  oversetmathrm= - left(nabla^2 J(bmx) right)^-1 nabla J(bmx)  \nendalign","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"function ∇²h(x)\n    return 12.0*x.^2 + 6.0*x - 2.0\nend\n\nxᵢ = 0.0\nnewton_step(xᵢ) = xᵢ - ∇²h(xᵢ)\\∇h(xᵢ)\n\n# Initial plot\nfig2 = Figure()\nax2 = Axis(fig2[1,1])\nlines!(ax2, x, h(x))\n\nxᵢ₊₁ = newton_step(xᵢ) \nplot!(ax2, [xᵢ], [h(xᵢ)], color=:orange, marker='x', markersize=25)\nxᵢ = xᵢ₊₁\nfig2","category":"page"},{"location":"5_optimization_methods/#Add-Regularization","page":"Optimization Methods","title":"Add Regularization","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"In the last example, our initialization violated our assumption of a positive semi-definite hessian","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"nabla^2 h(0) = -2","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"The first trick we can employ is regularization. The intuition is that we want to retain second order approximation of the function for better convergence, but the approximation must ensure that the direction of travel is still one of guaranteed descent.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Check out some of these visualizations for some of the details and play around with the regularization parameter.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"As mentioned on that page, solving for the regularization parameter is impractical: guess and check approximations to this value can be sufficient and are easily computable.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"using LinearAlgebra\n\nβ = 1.0\n\nfunction regularized_newton_step(xᵢ; β=β)\n    H = ∇²h(xᵢ)\n    while !isposdef(H) # don't do this in your own code!\n        H = H + β*I\n    end\n    return xᵢ - H\\∇h(xᵢ)\nend\n\n# Initial guess\nxᵢ = 0.0\n\n# Initial plot\nfig3 = Figure()\nax3 = Axis(fig3[1,1])\nlines!(ax3, x, h(x))\n\nxᵢ₊₁ = regularized_newton_step(xᵢ) \nplot!(ax3, [xᵢ], [h(xᵢ)], color=:orange, marker='x', markersize=25)\nxᵢ = xᵢ₊₁\nfig3","category":"page"},{"location":"5_optimization_methods/#How-can-this-go-wrong?","page":"Optimization Methods","title":"How can this go wrong?","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"For the regularization, we chose beta = 10 which worked well, but adding beta * bmI to our hessian until it is positive semi-definite could be bad. If the hessian has large negative eigenvalues, it can take a REALLY long time - linear in the magnitude of the smallest eigenvalue.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"In practice, we use additional information to choose a good beta, maybe guessing and checking a few times, and then regularize the quadratic - ideally in just a few guesses and checks.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"If we change the regularization parameter to something too high, this will have convergence no better than gradient descent. If it was too low (but the hessian was still positive semi-definite) we also observed overshoot.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Final note: regularization like this helps make the problem 'convex' in a way - another benefit to reap is that near flat areas, regularization can help ensure that the hessian does not become ill-conditioned.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"function h(x)\n    return 0.125 * x.^4 + sin.(3 * x) .+ 0.5  * x\nend\n\nfunction ∇h(x)\n    return 0.5 * x.^3 + 3 * cos.(3 * x) .+ 0.5\nend\n\nfunction ∇²h(x)\n    return 1.5 * x.^2 - 9 * sin.(3 * x)\nend\n\nx = range(-3.75,3.25,1000)\n\n# Initial guess\nx₀ = 0.0\n\nxᵢ = x₀\n\n# Initial plot\nfig4 = Figure()\nax4 = Axis(fig4[1,1])\nlines!(ax4, x, h(x))\n\nxᵢ₊₁ = regularized_newton_step(xᵢ; β=0.85)\nplot!(ax4, [xᵢ], [h(xᵢ)], color=:orange, marker='x', markersize=25)\nxᵢ = xᵢ₊₁\nfig4","category":"page"},{"location":"5_optimization_methods/#Add-line-search","page":"Optimization Methods","title":"Add line search","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Ok so that was bad, things went sideways and we were all over the place. This function was tailored to diverge with beta = 085. We want to make sure when we are taking a step, that the slope is not changing too quickly over the step. We want to take a step that sufficiently decreases the objective","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"function backtracking_regularized_newton_step(xᵢ)\n    H = ∇²h(xᵢ)\n\n    # regularization\n    β = 1.0\n    while !isposdef(H)\n        H = H + β*I\n    end\n    Δx = -H\\∇h(xᵢ)\n\n    # line search\n    b = 0.1\n    c = 0.25\n    α = 1.0\n    while h(xᵢ + α*Δx) > h(xᵢ) + b*α*∇h(xᵢ)*Δx\n        α = c*α\n    end\n    \n    return xᵢ + α*Δx\nend\n\n# Initial guess\nxᵢ = 0.0\n\n# Initial plot\nfig5 = Figure()\nax5 = Axis(fig5[1,1])\nlines!(ax5, x, h(x))\n\nxᵢ₊₁ = backtracking_regularized_newton_step(xᵢ) \nplot!(ax5, [xᵢ], [h(xᵢ)], color=:green, marker='x', markersize=25)\nxᵢ = xᵢ₊₁\nfig5","category":"page"},{"location":"5_optimization_methods/#Constrained-Optimization","page":"Optimization Methods","title":"Constrained Optimization","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"In this section, we are going to learn about constrained optimization. Let's keep things simple, and start without all of the regularization and line search stuff. ","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"In the next cells, we'll define a 2D bowl as our cost function, and we'll draw some nice level curves to visualize it–it's a convex cost, so we know it will have a minimum at the bottom of the bowl. To make it interesting, we will add a single constraint, which we draw as a curve.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"J(x y) = frac12 left( tfrac12 (x - 1)^2 + (y - 1)^2 right)","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"When constructing our system, to get to a minimum while respecting the constraints, we are using an augmented lagrangian. At each optimization step, we will enforce the constraints - more on this in a moment!","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"using ForwardDiff\n\nQ = Diagonal([0.5; 1])\n\n# Objective\nfunction J(x)\n    return 1 / 2 * (x - [1; 0])' * Q * (x - [1; 0])\nend\n\nfunction ∇J(x)\n    return Q * (x - [1; 0])\nend\n\nfunction ∇²J(x)\n    return Q\nend\n\n# Nonlinear constraint\nfunction f(x)\n    return x[1]^2 + 2*x[1] - x[2]\nend\n\nfunction ∂f(x)\n    return [2*x[1]+2 -1]\nend\n\nfunction draw_contour(ax; samples=40, levels=25)\n    cols = kron(ones(samples), range(-4, 4, samples)')\n    rows = kron(ones(samples)', range(-4, 4, samples))\n    vals = zeros(samples,samples)\n    for j = 1:samples\n        for k = 1:samples\n            vals[j, k] = J([cols[j, k]; rows[j, k]])\n        end\n    end\n    contour!(ax, vec(cols), vec(rows), vec(vals), levels=levels)\n\n    # Nonlinear x^2 + 2x - y = 0\n    constraint = range(-3.2, 1.2, samples)\n    lines!(ax, constraint, constraint.^2 .+ 2*constraint, color=:black, linewidth=2)\nend\n\nfunction newton_step(xᵢ, λᵢ)\n    ∂²L_∂x² = ∇²J(xᵢ) + ForwardDiff.jacobian(x -> ∂f(x)'λᵢ, xᵢ)\n    ∂f_∂x = ∂f(xᵢ)\n\n    # KKT system\n    H = [∂²L_∂x² ∂f_∂x'; ∂f_∂x 0]\n    g = [∇J(xᵢ) + ∂f_∂x'λᵢ; f(xᵢ)]\n    \n    Δz = -H\\g\n    Δx = Δz[1:2]\n    Δλ = Δz[3]\n    return xᵢ .+ Δx, λᵢ .+ Δλ\nend\n\nfig6 = Figure()\nax6 = Axis(fig6[1,1], aspect=1)\n\n# Initial guess\nxᵢ = Float64[-3; 2]\nλᵢ = Float64[0.0]\n\n# Draw the initial contours and the initial guess\ndraw_contour(ax6)\nplot!(ax6, [xᵢ[1]], [xᵢ[2]], color=:red, marker=:circle, markersize=15)\n\n# Perform Newton step\nxᵢ₊₁, λᵢ₊₁ = newton_step(xᵢ, λᵢ)\nplot!(ax6, [xᵢ₊₁[1]], [xᵢ₊₁[2]], color=:red, marker=:x, markersize=15)\nxᵢ .= xᵢ₊₁\nλᵢ .= λᵢ₊₁\n\nfig6","category":"page"},{"location":"5_optimization_methods/#Let's-talk-about-KKT-systems","page":"Optimization Methods","title":"Let's talk about KKT systems","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"We need regularization... even though we picked a convex cost! The constraint in our system makes this problem not convex anymore. Let's add regularization, but we will do so a bit differently.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"ASIDE Not in this talk, but that second term has other methods that can be used to approximate it (like LBFGS). LBFGS in particular has some robustness properties that baseline Newton's method lacks. We will make a similar approximation to our KKT system, called the Gauss-Newton approximation. See the exercises below for a more detailed explanation.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"The thought process is as follows: After inspecting ∂²L_∂x², we note that nabla^2 J is convex by construction. It is just the ForwardDiff.jacobian(x -> ∂f(x)'λᵢ, xᵢ) that causes trouble with the Hessian. At this time, we also notice that latter term is also expensive to compute. Because it causes trouble and is costly to compute, we decide to drop this term. This is the Gauss-Newton approximation. Its steps compute faster, but converge slower than Newton–luckily, the savings in compute speed often overtake any reduction in convergence rate!","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"function gauss_newton_step(xᵢ, λᵢ)\n    # Implicit regularization - drop the second-order constraint term\n    ∂²L_∂x² = ∇²J(xᵢ) \n    ∂f_∂x = ∂f(xᵢ)\n\n    # KKT system\n    H = [∂²L_∂x² ∂f_∂x'; ∂f_∂x 0]\n    g = [∇J(xᵢ) + ∂f_∂x'λᵢ; f(xᵢ)]\n    \n    Δz = -H\\g\n    Δx = Δz[1:2]\n    Δλ = Δz[3]\n    return xᵢ .+ Δx, λᵢ .+ Δλ\nend\n\nfig7 = Figure()\nax7 = Axis(fig7[1,1], aspect=1)\n\n# Initial guess\nxᵢ = Float64[-3; 2]\nλᵢ = Float64[0.0]\n\ndraw_contour(ax7)\nplot!(ax7, [xᵢ[1]], [xᵢ[2]], color=:green, marker=:circle, markersize=15)\n\n# Perform Gauss-Newton step\nxᵢ₊₁, λᵢ₊₁ = gauss_newton_step(xᵢ, λᵢ)\nplot!(ax7, [xᵢ₊₁[1]], [xᵢ₊₁[2]], color=:green, marker=:x, markersize=15)\nxᵢ .= xᵢ₊₁\nλᵢ .= λᵢ₊₁\n\nfig7","category":"page"},{"location":"5_optimization_methods/#The-Gauss-Newton-approximation","page":"Optimization Methods","title":"The Gauss-Newton approximation","text":"","category":"section"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"This quick calculation should hopefully remind you about the Gauss-Newton approximation.","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Start with a cost J(mathbfx). The necessary condition for optimality is nabla J(mathbfx) = 0. Our journey starts by asking what happens if J(mathbfx) is actually a least squares problem. For example, J(mathbfx) = frac12mathbfg(mathbfx)_2^2. ","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"nabla J(mathbfx) = fracpartial mathbfg(mathbfx)partial mathbfx^textT mathbfg(mathbfx)","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"nabla^2 J(mathbfx) = fracpartial mathbfg(mathbfx)partial mathbfx^textT fracpartial mathbfg(mathbfx)partial mathbfx + nablaleft(fracpartial mathbfg(mathbfx)partial mathbfx^textTright) mathbfg(mathbfx) approx fracpartial mathbfg(mathbfx)partial mathbfx^textT fracpartial mathbfg(mathbfx)partial mathbfx","category":"page"},{"location":"5_optimization_methods/","page":"Optimization Methods","title":"Optimization Methods","text":"Delta mathbfx = - left(fracpartial mathbfg(mathbfx)partial mathbfx^textT fracpartial mathbfg(mathbfx)partial mathbfxright)^-1\n    fracpartial mathbfg(mathbfx)partial mathbfx^textT mathbfg(mathbfx)","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#Nonlinear-Trajectory-Optimization-Lecture-3","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization - Lecture 3","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/#Getting-started","page":"Nonlinear Trajectory Optimization","title":"Getting started","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/#Review","page":"Nonlinear Trajectory Optimization","title":"Review","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Second order methods are important: We should always do this.\nProblem structure gave us a way to solve optimal control problems efficiently, with \"shooting\" or \"sparsity\".\nDirect optimal control is best if we aren't worried about real-time deployment.\nRecall the Newton's method with equality constraints, and the KKT system","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#Goals","page":"Nonlinear Trajectory Optimization","title":"Goals","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"We can go in two directions:\nsecond-order indirect (iLQR, DDP)\nsecond-order direct (Direct Collocation, Multiple Shooting).\nWe will focus on second-order direct.","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#I.-Nonlinear-Programming","page":"Nonlinear Trajectory Optimization","title":"I. Nonlinear Programming","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"A nonlinear program is a cost, equality constraint, and inequality constraint,","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    min_z quad f(z) \n    textstquad c(z) = 0 \n    quad d(z) le 0\nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Grab an off-the-shelf solver: IPOPT (free), SNOPT, KNITRO (commercial)","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#SQP-(Sequential-Quadratic-Programming)","page":"Nonlinear Trajectory Optimization","title":"SQP (Sequential Quadratic Programming)","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Take a second order Taylor expansion of the cost and linearize the constraints (locally about a guess):","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    min_z quad J(z) + g Delta z + tfrac12 Delta z^T H Delta z \n    textstquad c(z) + C Delta z = 0 \n    quad d(z) + D Delta z le 0\nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Lagrangian, mathcalL(z lambda mu) = J(z) + lambda^T c(z) + mu^T d(x)\nGradient: g = fracpartial mathcalLpartial z, Hessian: H = fracpartial^2 mathcalLpartial z^2, Jacobians: C = fracpartial cpartial z, D = fracpartial dpartial z\nSolve a QP to compute the primal-dual search direction, ","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Delta s = beginbmatrix \n        Delta z  Delta lambda  Delta mu\n    endbmatrix","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#Comments","page":"Nonlinear Trajectory Optimization","title":"Comments","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Play lots of tricks to leverage sparsity.\ntextSQP subset textSCP\n: Sequential Convex Programming puts constraints directly into the solver, without linearization.\nWe don't actually need rollouts: Direct Collocation maximally leverages this constraint structure.","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#Splines","page":"Nonlinear Trajectory Optimization","title":"Splines","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Cubic splines,","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    x(t) = a_0 + a_1 t + a_2 t^2 + a_3 t^3 \n    dotx(t) = phantoma_0 +  a_1 + 2 a_2 t + 3 a_3 t^2\nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Hermite splines use the left and right endpoint (x_n = x(t), x_n+1=x(t + h)), and their derivatives,","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    beginbmatrix\n        1  0  0  0 \n        0  1  0  0 \n        1  h  h^2  h^3 \n        0  1  2h  3 h^2\n    endbmatrix\n    beginbmatrix a_0  a_1  a_2  a_3 endbmatrix\n    = \n    beginbmatrix x_n  dotx_n  x_n+1  dotx_n+1 endbmatrix \nRightarrow\n    beginbmatrix\n        1  0  0  0 \n        0  1  0  0 \n        -tfrac3h^2  -tfrac2h  tfrac3h^2  -tfrac1h \n        tfrac2h^3  tfrac1h^2  -tfrac2h^3  tfrac1h^2\n    endbmatrix\n    beginbmatrix x_n  dotx_n  x_n+1  dotx_n+1 endbmatrix\n    = \n    beginbmatrix a_0  a_1  a_2  a_3 endbmatrix\nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"The collocation point enforces the dynamics constraint using the value at some other point (the spline required free variables!),","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    x(t + tfrach2) = tfrac12(x_n + x_n+1) + tfrach8 (dotx_n - dotx_n+1) \n    = tfrac12(x_n + x_n+1) + tfrach8 (f(x_n u_n) - f(x_n+1 u_n+1))\n     \n    u(t + tfrach2) = tfrac12 (u_n + u_n+1) \n     \n    dotx(t + tfrach2) = -tfrac32h(x_n - x_n+1) - tfrac14 (dotx_n + dotx_n+1) \n     = -tfrac32h(x_n - x_n+1) - tfrac14 (f(x_n u_n) + f(x_n+1 u_n+1)) \nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Putting the dynamics into the constraint,","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"beginalign\n    C_n(z) = C_n(x_n u_n x_n+1 u_n+1) \n    = f(x_n + 12 u_n + 12) - dotx_n + 12 \n    = fleft( tfrac12(x_n + x_n+1) + tfrach8 (f(x_n u_n) - f(x_n+1 u_n+1)) tfrac12 (u_n + u_n+1) right) quad- left(-tfrac32h(x_n - x_n+1) - tfrac14 (f(x_n u_n) + f(x_n+1 u_n+1)) right) \n    quad overset= 0\nendalign","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"Achieves 3rd order accuracy (RK4 is Runge-Kutta 4th Order).\nRequires fewer f calls than RK3. Exercise: How?","category":"page"},{"location":"8_nonlinear_trajectory_optimization/#II.-IPOPT","page":"Nonlinear Trajectory Optimization","title":"II. IPOPT","text":"","category":"section"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"From the IPOPT documentation (https://coin-or.github.io/Ipopt/OUTPUT.html):","category":"page"},{"location":"8_nonlinear_trajectory_optimization/","page":"Nonlinear Trajectory Optimization","title":"Nonlinear Trajectory Optimization","text":"inf_pr: The unscaled constraint violation at the current point. This quantity is the infinity-norm (max) of the (unscaled) constraints (g_Lg(x)g_U in (NLP)). During the restoration phase, this value remains the constraint violation of the original problem at the current point. The option infproutput can be used to switch to the printing of a different quantity.\ninf_du: The scaled dual infeasibility at the current point. This quantity measure the infinity-norm (max) of the internal dual infeasibility, Eq. (4a) in the implementation paper [12], including inequality constraints reformulated using slack variables and problem scaling. During the restoration phase, this is the value of the dual infeasibility for the restoration phase problem.\nlg(mu): log10 of the value of the barrier parameter μ.\n||d||: The infinity norm (max) of the primal step (for the original variables x and the internal slack variables s). During the restoration phase, this value includes the values of additional variables, p and n (see Eq. (30) in [12]).\nlg(rg): log10 of the value of the regularization term for the Hessian of the Lagrangian in the augmented system (δw in Eq. (26) and Section 3.1 in [12]). A dash (\"-\") indicates that no regularization was done.\nalpha_du: The stepsize for the dual variables (αzk in Eq. (14c) in [12]).","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Introduction-to-state-vector-simulation","page":"Introduction to State Vector Simulation","title":"Introduction to state vector simulation","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"In this lesson, we're going to implement a simple state vector simulator and steadily made it less simple (and more performant) as a way to examine some performance guidelines for Julia and numerical physics.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"First, let's remind ourselves of some basic facts about state vectors.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#State-vectors,-gates,-and-observables","page":"Introduction to State Vector Simulation","title":"State vectors, gates, and observables","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/#State-vector-basics","page":"Introduction to State Vector Simulation","title":"State vector basics","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"A state vector is a length-D^N complex vector representing probability amplitudes for a quantum system of N particles, each with D possible states. So, for qubits, which have 2 possible states (0rangle and 1rangle), the state vector has 2^N elements, and for qutrits, which have 3 possible states, the state vector would have 3^N elements.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"In this lecture we'll focus entirely on the qubit case, as it's most common.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For just a single qubit, we have a 2-element vector:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"psi_1rangle = beginbmatrix psi_0  psi_1 endbmatrix","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Where this corresponds to ","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"psi_1rangle = psi_0  0 rangle + psi_1  1 rangle","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For two qubits, we have a 4-element vector:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"psi_2rangle = beginbmatrix psi_00  psi_01  psi_10  psi_11 endbmatrix","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Where this corresponds to","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"psi_2rangle = psi_00  00 rangle + psi_01  01 rangle + psi_10  10 rangle + psi_11  11 rangle","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For N qubits, the state vector has 2^N elements. We can think of the index within the vector as corresponding to a base-2 representation of the computational basis. So for a vector with index i, we have the state irangle = i_N-1  i_0rangle.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Gate-application","page":"Introduction to State Vector Simulation","title":"Gate application","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Gates are unitary matrices that transform state vectors. For a single qubit system, gates are 2 times 2 matrices. For an N-qubit system, gates are 2^N times 2^N matrices.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"In Julia, we'll represent our single-qubit gates as follows:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"using LinearAlgebra\nusing Chairmarks\nusing Profile\nusing AliasTables","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"const X = float.(complex.([0 1; 1 0]))\nconst Y = float.([0 -im; im 0])\nconst Z = float.(complex.([1 0; 0 -1]))\nconst I = float.(complex.([1 0; 0 1]))\nconst H = float.(complex.(1/√2 * [1 1; 1 -1]))","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Most quantum gates act on a single qubit, but the state vector involves many qubits. We can extend a single-qubit gate to act on the entire state vector by taking a tensor product with the identity matrix for all other qubits.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For example, if we have a 3-qubit state vector and we want to apply gate G to the second qubit (qubit 1), we need to apply I otimes G otimes I to the state vector. In Julia, the tensor product is implemented as kron.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_naive(ψ::Vector, gate::Matrix, gate_qubit::Int)\n    n_qubits  = Int( log2(length(ψ)) )\n    all_gates = [I for qubit in 1:n_qubits]\n    all_gates[n_qubits - gate_qubit] = gate # Julia is one indexed!\n    full_gate = reduce(kron, all_gates)\n    return full_gate * ψ\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's test this with a simple example. We'll create a 3-qubit state vector and apply an X gate to the second qubit:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Create a 3-qubit state vector in the |000⟩ state\nψ = zeros(ComplexF64, 8)\nψ[1] = 1.0  # |000⟩ corresponds to index 1","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Apply X gate to qubit 1 (second qubit)\nψ_new = apply_gate_naive(ψ, X, 1)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# This should give us |010⟩, which corresponds to index 3\nfindall(x -> abs(x) > 1e-10, ψ_new)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Observables","page":"Introduction to State Vector Simulation","title":"Observables","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Observables are Hermitian matrices that correspond to measurable quantities. For a single qubit, common observables are the Pauli matrices X, Y, and Z.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"The expectation value of an observable O on a state vector psirangle is:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"langle O rangle = langle psi  O  psi rangle","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For a multi-qubit system, we need to extend the observable to act on the entire state vector using tensor products, just like we did for gates.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function expectation_value_naive(ψ::Vector, observable::Matrix, observable_qubit::Int)\n    n_qubits  = Int( log2(length(ψ)) )\n    all_observables = [I for qubit in 1:n_qubits]\n    all_observables[n_qubits - observable_qubit] = observable\n    full_observable = reduce(kron, all_observables)\n    return real(ψ' * full_observable * ψ)\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's test this with our X gate example:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Expectation value of Z on qubit 1 for |000⟩\nexpectation_value_naive(ψ, Z, 1)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Expectation value of Z on qubit 1 for |010⟩\nexpectation_value_naive(ψ_new, Z, 1)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Performance-considerations","page":"Introduction to State Vector Simulation","title":"Performance considerations","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"The naive approach works, but it's not very efficient. The main problem is that we're creating a large matrix (2^N times 2^N) for each gate application, which becomes prohibitively expensive for large systems.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's create a larger system to see the performance issues:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"n_qubits = 8\nψ_large = zeros(ComplexF64, 2^n_qubits)\nψ_large[1] = 1.0","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# This will be slow and memory-intensive\n@b apply_gate_naive(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For a 16-qubit system, we need to create a 65536 times 65536 matrix, which uses about 34 GB of memory! This is clearly not sustainable.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Optimized-approaches","page":"Introduction to State Vector Simulation","title":"Optimized approaches","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"The key insight is that we don't need to create the full matrix. Instead, we can directly manipulate the state vector using more efficient algorithms.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Approach-1:-Tensor-reshaping","page":"Introduction to State Vector Simulation","title":"Approach 1: Tensor reshaping","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"One approach is to reshape the state vector into a tensor and apply gates more efficiently:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_reshaped1(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n_qubits = Int(log2(length(ψ)))\n    \n    # Reshape the state vector into a tensor\n    tensor_shape = ntuple(i -> 2, n_qubits)\n    ψ_tensor = reshape(ψ, tensor_shape)\n    \n    # Apply the gate to the specified qubit\n    result = similar(ψ_tensor)\n    \n    # We need to contract the gate with the appropriate tensor dimension\n    # This is a simplified version - full implementation would be more complex\n    \n    return vec(result)\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"A more direct approach is to use the structure of the tensor product:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_reshaped2(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n_qubits = Int(log2(length(ψ)))\n    \n    # Create a copy of the state vector\n    ψ_new = copy(ψ)\n    \n    # The key insight is that we can operate on chunks of the state vector\n    chunk_size = 2^gate_qubit\n    stride = 2^(gate_qubit + 1)\n    \n    for i in 1:chunk_size:length(ψ)\n        # Apply the gate to this chunk\n        if i + chunk_size - 1 <= length(ψ)\n            # Get the two components for this qubit\n            α = ψ[i:i+chunk_size-1]\n            β = ψ[i+chunk_size:min(i+stride-1, length(ψ))]\n            \n            # Apply the gate\n            ψ_new[i:i+chunk_size-1] = gate[1,1] * α + gate[1,2] * β\n            if i + stride - 1 <= length(ψ)\n                ψ_new[i+chunk_size:i+stride-1] = gate[2,1] * α + gate[2,2] * β\n            end\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Approach-2:-Bit-manipulation","page":"Introduction to State Vector Simulation","title":"Approach 2: Bit manipulation","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"A more efficient approach uses bit manipulation to directly compute which elements of the state vector need to be modified:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_shifting1(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n = length(ψ)\n    ψ_new = copy(ψ)\n    \n    for i in 0:(n-1)\n        # Check if the gate_qubit is 0 or 1 in the binary representation of i\n        if (i >> gate_qubit) & 1 == 0\n            # The qubit is 0, so we need to find the corresponding 1 state\n            j = i | (1 << gate_qubit)  # Set the gate_qubit to 1\n            \n            # Apply the gate\n            α = ψ[i+1]  # +1 because Julia is 1-indexed\n            β = ψ[j+1]\n            \n            ψ_new[i+1] = gate[1,1] * α + gate[1,2] * β\n            ψ_new[j+1] = gate[2,1] * α + gate[2,2] * β\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's test this implementation:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"ψ_test = zeros(ComplexF64, 8)\nψ_test[1] = 1.0","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Apply X gate to qubit 1\nψ_result = apply_gate_shifting1(ψ_test, X, 1)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Compare with naive implementation\nψ_naive = apply_gate_naive(ψ_test, X, 1)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Check if they're the same\nmaximum(abs.(ψ_result - ψ_naive))","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Great! Now let's benchmark the performance:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"@b apply_gate_shifting1(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"This is much faster than the naive approach! But we can do even better.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Optimized-bit-manipulation","page":"Introduction to State Vector Simulation","title":"Optimized bit manipulation","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"We can optimize the bit manipulation approach by eliminating redundant work:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_shifting2(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n = length(ψ)\n    ψ_new = copy(ψ)\n    \n    mask = 1 << gate_qubit\n    \n    for i in 0:(n-1)\n        if (i & mask) == 0  # Only process when the target qubit is 0\n            j = i | mask    # Corresponding index with target qubit = 1\n            \n            α = ψ[i+1]\n            β = ψ[j+1]\n            \n            ψ_new[i+1] = gate[1,1] * α + gate[1,2] * β\n            ψ_new[j+1] = gate[2,1] * α + gate[2,2] * β\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"@b apply_gate_shifting2(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"We can make this even more efficient by using vectorized operations:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_shifting_linear(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n = length(ψ)\n    ψ_new = copy(ψ)\n    \n    # Create masks for efficient bit manipulation\n    mask = 1 << gate_qubit\n    \n    # Process in chunks to utilize vectorization\n    chunk_size = 2^(gate_qubit + 1)\n    lower_chunk = 2^gate_qubit\n    \n    for start in 0:chunk_size:(n-1)\n        # Process the chunk\n        for i in start:(start + lower_chunk - 1)\n            if i + lower_chunk < n\n                j = i + lower_chunk\n                \n                α = ψ[i+1]\n                β = ψ[j+1]\n                \n                ψ_new[i+1] = gate[1,1] * α + gate[1,2] * β\n                ψ_new[j+1] = gate[2,1] * α + gate[2,2] * β\n            end\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"@b apply_gate_shifting_linear(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Threading-for-additional-performance","page":"Introduction to State Vector Simulation","title":"Threading for additional performance","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For very large systems, we can use threading to parallelize the computation:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_threaded(ψ::Vector{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n = length(ψ)\n    ψ_new = copy(ψ)\n    \n    chunk_size = 2^(gate_qubit + 1)\n    lower_chunk = 2^gate_qubit\n    \n    Threads.@threads for start in 0:chunk_size:(n-1)\n        for i in start:(start + lower_chunk - 1)\n            if i + lower_chunk < n\n                j = i + lower_chunk\n                \n                α = ψ[i+1]\n                β = ψ[j+1]\n                \n                ψ_new[i+1] = gate[1,1] * α + gate[1,2] * β\n                ψ_new[j+1] = gate[2,1] * α + gate[2,2] * β\n            end\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"@b apply_gate_threaded(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Performance-comparison","page":"Introduction to State Vector Simulation","title":"Performance comparison","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's compare all our implementations:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"println(\"Naive approach:\")\n@b apply_gate_naive(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"println(\"Bit shifting approach:\")\n@b apply_gate_shifting_linear(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"println(\"Threaded approach:\")\n@b apply_gate_threaded(ψ_large, X, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Expectation-values","page":"Introduction to State Vector Simulation","title":"Expectation values","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"We can apply similar optimizations to expectation value calculations:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function expectation_value_optimized(ψ::Vector{ComplexF64}, observable::Matrix{ComplexF64}, observable_qubit::Int)\n    n = length(ψ)\n    result = 0.0\n    \n    chunk_size = 2^(observable_qubit + 1)\n    lower_chunk = 2^observable_qubit\n    \n    for start in 0:chunk_size:(n-1)\n        for i in start:(start + lower_chunk - 1)\n            if i + lower_chunk < n\n                j = i + lower_chunk\n                \n                α = ψ[i+1]\n                β = ψ[j+1]\n                \n                # Compute the expectation value contribution\n                result += real(conj(α) * observable[1,1] * α + \n                              conj(α) * observable[1,2] * β +\n                              conj(β) * observable[2,1] * α + \n                              conj(β) * observable[2,2] * β)\n            end\n        end\n    end\n    \n    return result\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Test the optimized expectation value\nexpectation_value_optimized(ψ_large, Z, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Compare with naive implementation\nexpectation_value_naive(ψ_large, Z, 4)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Multi-qubit-gates","page":"Introduction to State Vector Simulation","title":"Multi-qubit gates","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For multi-qubit gates (like CNOT), we need to extend our approach:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_cnot(ψ::Vector{ComplexF64}, control_qubit::Int, target_qubit::Int)\n    n = length(ψ)\n    ψ_new = copy(ψ)\n    \n    control_mask = 1 << control_qubit\n    target_mask = 1 << target_qubit\n    \n    for i in 0:(n-1)\n        # Only apply if control qubit is 1\n        if (i & control_mask) != 0\n            # Find the index with target qubit flipped\n            j = i ⊻ target_mask  # XOR flips the target bit\n            \n            # Swap the amplitudes\n            ψ_new[i+1] = ψ[j+1]\n            ψ_new[j+1] = ψ[i+1]\n        end\n    end\n    \n    return ψ_new\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Test CNOT gate\nψ_cnot_test = zeros(ComplexF64, 4)\nψ_cnot_test[3] = 1.0  # |10⟩ state","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Apply CNOT with control=1, target=0\nψ_cnot_result = apply_cnot(ψ_cnot_test, 1, 0)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Sampling-from-quantum-states","page":"Introduction to State Vector Simulation","title":"Sampling from quantum states","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Often in quantum simulation, we need to sample from the probability distribution defined by the state vector:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function naive_sample(ψ::Vector{ComplexF64}, n_shots::Int)\n    probabilities = abs2.(ψ)\n    samples = Int[]\n    \n    for _ in 1:n_shots\n        r = rand()\n        cumulative = 0.0\n        \n        for (i, p) in enumerate(probabilities)\n            cumulative += p\n            if r <= cumulative\n                push!(samples, i-1)  # Convert to 0-indexed\n                break\n            end\n        end\n    end\n    \n    return samples\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Test sampling\nsamples = naive_sample(ψ_large, 1000)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Count the frequency of each outcome\nusing StatsBase\ncountmap(samples)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For better performance with many samples, we can use the alias method:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function alias_sample(ψ::Vector{ComplexF64}, n_shots::Int)\n    probabilities = abs2.(ψ)\n    \n    # Create alias table\n    alias_table = AliasTables.AliasTable(probabilities)\n    \n    # Sample from the alias table\n    samples = [rand(alias_table) - 1 for _ in 1:n_shots]  # Convert to 0-indexed\n    \n    return samples\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Test alias sampling\nalias_samples = alias_sample(ψ_large, 1000)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Compare performance\n@b naive_sample(ψ_large, 1000)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"@b alias_sample(ψ_large, 1000)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Mixed-states-and-density-matrices","page":"Introduction to State Vector Simulation","title":"Mixed states and density matrices","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For mixed states, we need to work with density matrices instead of state vectors:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function apply_gate_density_matrix(ρ::Matrix{ComplexF64}, gate::Matrix{ComplexF64}, gate_qubit::Int)\n    n_qubits = Int(log2(size(ρ, 1)))\n    \n    # Create the full gate matrix\n    all_gates = [I for qubit in 1:n_qubits]\n    all_gates[n_qubits - gate_qubit] = gate\n    full_gate = reduce(kron, all_gates)\n    \n    # Apply the gate: ρ_new = U * ρ * U†\n    return full_gate * ρ * full_gate'\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Create a mixed state (50% |0⟩ and 50% |1⟩)\nρ_mixed = zeros(ComplexF64, 2, 2)\nρ_mixed[1,1] = 0.5  # |0⟩⟨0|\nρ_mixed[2,2] = 0.5  # |1⟩⟨1|","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Apply Hadamard gate\nρ_mixed_h = apply_gate_density_matrix(ρ_mixed, H, 0)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Putting-it-all-together:-Circuit-simulation","page":"Introduction to State Vector Simulation","title":"Putting it all together: Circuit simulation","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's create a simple function to simulate a quantum circuit:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"function simulate_circuit(initial_state::Vector{ComplexF64}, gates::Vector{Tuple{Matrix{ComplexF64}, Int}})\n    ψ = copy(initial_state)\n    \n    for (gate, qubit) in gates\n        ψ = apply_gate_shifting_linear(ψ, gate, qubit)\n    end\n    \n    return ψ\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Create a Bell state circuit: H on qubit 1, then CNOT(1,0)\ninitial_state = zeros(ComplexF64, 4)\ninitial_state[1] = 1.0  # |00⟩\n\n# Define the circuit\ncircuit = [(H, 1)]  # Apply H to qubit 1","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Run the first part of the circuit\nψ_after_h = simulate_circuit(initial_state, circuit)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Now apply CNOT manually (since we need a specialized function)\nbell_state = apply_cnot(ψ_after_h, 1, 0)","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Verify this is a Bell state\nprintln(\"Bell state amplitudes:\")\nfor (i, amp) in enumerate(bell_state)\n    if abs(amp) > 1e-10\n        println(\"State |$(bitstring(i-1)[end-1:end])⟩: \", amp)\n    end\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Performance-profiling","page":"Introduction to State Vector Simulation","title":"Performance profiling","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Let's profile our optimized gate application to see where time is spent:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Profile the optimized gate application\nProfile.clear()\n@profile for i in 1:1000\n    apply_gate_shifting_linear(ψ_large, X, 4)\nend","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"# Display profiling results\nProfile.print()","category":"page"},{"location":"2_introduction_to_state_vector_simulation/#Final-thoughts","page":"Introduction to State Vector Simulation","title":"Final thoughts","text":"","category":"section"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"This tutorial has shown how to implement efficient quantum state vector simulation in Julia. Key takeaways:","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"Avoid creating large matrices: Use bit manipulation instead of tensor products\nVectorize operations: Process data in chunks when possible\nUse threading: For large systems, parallel processing can provide significant speedups\nProfile your code: Use Julia's profiling tools to identify bottlenecks\nConsider specialized algorithms: For sampling, use techniques like the alias method","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"The optimized implementations we've developed can handle reasonably large quantum systems (up to ~20-25 qubits) efficiently, making them suitable for many quantum algorithm simulations and educational purposes.","category":"page"},{"location":"2_introduction_to_state_vector_simulation/","page":"Introduction to State Vector Simulation","title":"Introduction to State Vector Simulation","text":"For production quantum simulation, you would typically use specialized libraries like Yao.jl or PennyLane.jl, but understanding these fundamental algorithms helps you use such libraries more effectively and debug performance issues.","category":"page"},{"location":"7_trajectory_optimization/#Trajectory-Optimization-Lecture-2","page":"Trajectory Optimization","title":"Trajectory Optimization - Lecture 2","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"using Optim\nusing LinearAlgebra\nusing SparseArrays\nusing CairoMakie\nusing Piccolo\n\n# let's define a shorthand for kron\nconst ⊗ = kron","category":"page"},{"location":"7_trajectory_optimization/#Getting-started","page":"Trajectory Optimization","title":"Getting started","text":"","category":"section"},{"location":"7_trajectory_optimization/#Review","page":"Trajectory Optimization","title":"Review","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Gradient descent\nNewton's method and KKT conditions\nRegularization\nNewton approximations\nLine search","category":"page"},{"location":"7_trajectory_optimization/#Goals","page":"Trajectory Optimization","title":"Goals","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Introduce trajectory optimization\nSolve the LQR problem three ways\nDescribe nonlinear trajectory optimization","category":"page"},{"location":"7_trajectory_optimization/#I.-Trajectory-optimization","page":"Trajectory Optimization","title":"I. Trajectory optimization","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"The solution is a definite trajectory, not a feedback policy.","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\nmin_x_1N u_1N quad J(x_1N u_1N) = sum_n=1^N ell_n(x_n u_n) + ell_N(x_N u_N) \ntextst quad x_n+1 = f(x_n u_n n)\nendalign","category":"page"},{"location":"7_trajectory_optimization/#Named-Trajectories","page":"Trajectory Optimization","title":"Named Trajectories","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Terminology","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Snapshot matrix, Z = beginbmatrix        z_1  z_2   z_T        endbmatrix\nKnot point, z_1 = beginbmatrix x_1  u_1 endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"N = 10 # Number of knot points\ntraj = rand(NamedTrajectory, N)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"traj.x","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"traj.u","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"plot(traj, :x)","category":"page"},{"location":"7_trajectory_optimization/#II.-Linear-Quadratic-Regulator","page":"Trajectory Optimization","title":"II. Linear Quadratic Regulator","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"LQR is the \"simple harmonic oscillator\" of control","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\nmin_x_1N u_1N-1 quad J = sum_n=1^N-1 tfrac12 x_n^T Q_n x_n + tfrac12 u_n^T R_n u_n + tfrac12 x_N^T Q_N x_N \ntextst quad x_n+1 = A_n x_n + B_n u_n \nquad Q_n succeq 0 R_n succ 0\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Quick check: Why does R need to be positive definite?","category":"page"},{"location":"7_trajectory_optimization/#Linear-systems","page":"Trajectory Optimization","title":"Linear systems","text":"","category":"section"},{"location":"7_trajectory_optimization/#Zero-order-hold","page":"Trajectory Optimization","title":"Zero-order hold","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Zero-order hold can be used to convert continuous, linear, time-invariant (LTI) systems to discrete LTI systems.","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\ndotx(t) = A x(t) + B u(t)  \noversethlongrightarrow x(t+h) = A_h x(t) + B_h u(t) \n= left( sum_nge0 tfrac1n A^n h^n right) x + left( sum_nge1 tfrac1n A^n-1 B h^n right) u \napprox (I + h A) x + h B u\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Matrix exponential trick:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"expleft(beginbmatrix A  B  0  0 endbmatrix h right)\n= beginbmatrix A_h  B_h  0  I endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"# Define continuous LTI system matrices\nA = [0.0 1.0; -1.0 -0.1]\nB = [0.0; 1.0]\nh = 0.1  # Time step\n\nfunction continuous_to_discrete(A, B, h)\n    # Construct augmented matrix for matrix exponential\n    augmented_matrix = [\n        A B; \n        zeros(size(B, 2), size(A, 1)) zeros(size(B, 2), size(B, 2))\n    ]\n\n    # Compute matrix exponential\n    exp_matrix = exp(augmented_matrix * h)\n\n    # Extract discrete LTI system matrices\n    A_h = exp_matrix[1:size(A, 1), 1:size(A, 2)]\n    B_h = exp_matrix[1:size(A, 1), size(A, 2)+1:end]\n\n    return A_h, B_h\nend\n\n# Extract discrete LTI system matrices\nA_h, B_h = continuous_to_discrete(A, B, h);","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"A_h","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"I + A * h","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"B_h","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"B * h","category":"page"},{"location":"7_trajectory_optimization/#Double-Integrator","page":"Trajectory Optimization","title":"Double Integrator","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Double integrator (Newton's second law, F = ma)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"m fracddt beginbmatrix q  dotq endbmatrix \n= beginbmatrix 0  m  0  0 endbmatrix beginbmatrix q  dotq endbmatrix\n+ beginbmatrix 0  u endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"function double_integrator(m)\n    A_c = [0.0 1.0; 0.0 0.0]\n    B_c = [0.0; 1.0 / m]\n    return A_c, B_c\nend\n\n# simulate a discrete LTI system\nfunction simulate_dlti(u::AbstractMatrix, A, B, x1)\n    N = size(u, 2) + 1\n    x = zeros(size(A, 2), N)\n    x[:, 1] = x1\n    for k in 1:N-1\n        x[:, k + 1] = A * x[:, k] + B * u[:, k]\n    end\n    return x\nend\n\nfunction simulate_dlti(u::AbstractVector, A, B, x1)\n    simulate_dlti(reshape(u, 1, length(u)), A, B, x1)\nend","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"m = 2.0 # Mass\nA_c , B_c = double_integrator(m)\nh = 0.05  # Time step\nA, B = continuous_to_discrete(A_c, B_c, h);","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"A ≈ I + A_c * h","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"B ≈ B_c * h + [h^2 / 2m; 0]","category":"page"},{"location":"7_trajectory_optimization/#Indirect-optimal-control:-Naive-way","page":"Trajectory Optimization","title":"Indirect optimal control: Naive way","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Indirect optimal control is also known as \"single shooting\"\nThe naive way is to perform gradient descent without any problem structure.","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"min_u_1N-1 quad J(u_1N-1) = sum_n=1^N-1 ell_n(x_n(u_1n-1) u_n) + ell_N(x_N(u_1N-1) u_N)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"We will start with the double integrator and solve the LQR problem,","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\nmin_u_1N-1 quad J(u_1N-1) = sum_n=1^N-1 tfrac12 x_n(u_1n-1)^T Q_n x_n(u_1n-1) + tfrac12 u_n^T R_n u_n + tfrac12 x_N(u_1N-1)^T Q_N x_N(u_1N-1) \ntextst quad Q_n succeq 0 R_n succ 0\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"m = 0.1 # Mass\nA_c, B_c = double_integrator(m)\nh = 0.1  # Time step\nA, B = continuous_to_discrete(A_c, B_c, h)\nx1 = [1.0; 2.0]  # Initial state\n\nQ = 1e-4I\nR = 1e-1I\nQN = 1e2I\n\nfunction J(\n    x::AbstractMatrix,\n    u::AbstractVecOrMat;\n    Q = 1e-2I, \n    R = 1e-4I, \n    QN = 1e2I\n)\n    u = isa(u, AbstractMatrix) ? u : reshape(u, 1, length(u))\n    \n    N = size(u, 2) + 1    \n    J = 0.0\n    for n in 1:N-1\n        xₙ = x[:, n]\n        uₙ = u[:, n]\n        J += 1/2 * (xₙ' * Q * xₙ + uₙ' * R * uₙ)\n    end\n    J += 1/2 * (x[:, N]' * QN * x[:, N])\n    return J\nend\n\nfunction J(u::AbstractVecOrMat; A=A, B=B, x1=x1, kwargs...)\n    x = simulate_dlti(u, A, B, x1)\n    return J(x, u; kwargs...)\nend","category":"page"},{"location":"7_trajectory_optimization/#Gradient-descent","page":"Trajectory Optimization","title":"Gradient descent","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"N = 40\nu0 = randn(N - 1)\nJ(u0; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"fig, ax = series(simulate_dlti(u0, A, B, x1), labels=[\"q\", \"q̇\"])\naxislegend(ax)\nfig","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"res = optimize(u -> J(u; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN), u0, GradientDescent(), \n               Optim.Options(iterations=50))","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"fig, ax = series(simulate_dlti(res.minimizer, A, B, x1), labels=[\"q\", \"q̇\"])\naxislegend(ax)\nfig","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"stairs(res.minimizer)","category":"page"},{"location":"7_trajectory_optimization/#Newton's-method","page":"Trajectory Optimization","title":"Newton's method","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"res_newton = optimize(u -> J(u; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN), u0, Newton(),\n                     Optim.Options(iterations=20))","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"fig, ax = series(simulate_dlti(res_newton.minimizer, A, B, x1), labels=[\"q\", \"q̇\"])\naxislegend(ax)\nfig","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"stairs(res_newton.minimizer)","category":"page"},{"location":"7_trajectory_optimization/#Indirect-optimal-control:-Pontryagin","page":"Trajectory Optimization","title":"Indirect optimal control: Pontryagin","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Tagline","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"\"optimize, then discretize\"","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Ideas","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"We can do this in a smart way by using the temporal structure of the problem.","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\nmin_x_1N u_1N-1  quad J(x_1N u_1N-1) = sum_n=1^N-1 tfrac12 x_n^T Q_n x_n + tfrac12 u_n^T R_n u_n + tfrac12 x_N^T Q_N x_N \ntextst quad x_n+1 = A_n x_n + B_n u_n \nquad Q_n succeq 0 R_n succ 0\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Lagrangian:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"L(x_1N u_1N-1 lambda_2N) = sum_n=1^N-1 tfrac12 x_n^T Q_n x_n + tfrac12 u_n^T R_n u_n + lambda_n+1^T(A_n x_n + B_n u_n - x_n+1) + tfrac12 x_N^T Q_N x_N","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"KKT conditions:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\n    fracpartial Lpartial lambda_n = (A_n x_n + B_n u_n - x_n+1)^T overset= 0 \n    fracpartial Lpartial x_n = x_n^T Q_n + lambda_n+1^T A_n - lambda_n^T overset= 0 \n    fracpartial Lpartial x_N = x_N^T Q_N - lambda_N^T overset= 0 \n    fracpartial Lpartial u_n = u_n^T R_n + lambda_n+1^T B_n overset= 0\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Rewrite:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\n    x_n+1 = A_n x_n + B_n u_n \n    lambda_n = A_n^T lambda_n+1 + Q_n x_n \n    lambda_N = Q_N x_N \n    u_n = -R_n^-1 B_n^T lambda_n+1\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"There is a forward equation and a backward equation. This computation is backpropagation through time.\nWe inherit many of the same problems, e.g., vanishing / exploding gradients.","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"N = 60\nm = 1.0 # Mass\nA_c, B_c = double_integrator(m)\nh = 0.1  # Time step\nA, B = continuous_to_discrete(A_c, B_c, h)\nx1 = [1.0; 1.0]  # Initial state\n\nQ = 1e-4I\nR = 1e-2I\nQN = 1e1I\n\n# Initial guess\nu = zeros(1, N - 1)\nΔu = ones(1, N - 1)\nx = simulate_dlti(u, A, B, x1)\nλ = zeros(size(x, 1), N)\n\n# Line search parameters\nα = 1.0 # Step size\nb = 1e-2 # Tolerance\nα_min = 1e-16 # Minimum step size\nloop = 0\nmax_iterations = 20\n\n# Verbose\nverbose = false\n\nwhile maximum(abs, Δu) > 1e-2 && α > α_min && loop < max_iterations\n    verbose ? println(\"Iteration: \", loop) : nothing\n\n    # Backward pass to compute λ and Δu\n    λ[:, N] .= QN * x[:, N]\n    for n = N-1:-1:1\n        Δu[:, n] .= - R\\B' * λ[:, n+1] - u[:, n]\n        λ[:, n] .= Q * x[:, n] + A' * λ[:, n+1]\n    end\n\n    # Forward pass (with line search) to compute x\n    global α = 1.0\n    b = 1e-2 # Tolerance\n    unew = u + α .* Δu\n    xnew = simulate_dlti(unew, A, B, x1)\n    \n    while J(xnew, unew) > J(x, u) - b * α * norm(Δu)^2\n        α = 0.5 * α\n        unew = u + α .* Δu\n        xnew = simulate_dlti(unew, A, B, x1)\n\n        if verbose && α < α_min\n            println(\"\\tLine search failed to find a suitable step size\")\n            break\n        end\n    end\n\n    u .= unew\n    x .= xnew #added this dot so that global x is modified (https://discourse.julialang.org/t/local-and-global-variables-with-the-same-name-error-undefvarerror-x-not-defined/53951)\n    verbose ? println(\"\\tα = \", α) : nothing\n\n    global loop = loop + 1\nend","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"series(simulate_dlti(u, A, B, x1))","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"stairs(u[1, :])","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Exercise: Neural ODEs","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Check out this SciML note. Can we connect what we learned about Pontryagin to this work?","category":"page"},{"location":"7_trajectory_optimization/#Direct-optimal-control","page":"Trajectory Optimization","title":"Direct optimal control","text":"","category":"section"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Tagline","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"\"discretize, then optimize\"","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Ideas","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Package the optimization variables into a trajectory\nSet up a quadratic program defined over the trajectory\nObserve the presence of sparsity","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\nmin_x_1N u_1N-1 quad J(x_1N u_1N-1) = sum_n=1^N-1 tfrac12 x_n^T Q_n x_n + tfrac12 u_n^T R_n u_n + tfrac12 x_N^T Q_N x_N \ntextst quad x_n+1 = A_n x_n + B_n u_n \nquad Q_n succeq 0 R_n succ 0\nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"m = 0.1 # Mass\nA_c, B_c = double_integrator(m)\nh = 0.1  # Time step\nA, B = sparse.(continuous_to_discrete(A_c, B_c, h))\nx1 = [1.0; 1.0]  # Initial state\n\nN = 100\nx_dim = size(A, 2)\nu_dim = size(B, 2)\n\nQ = sparse(1e-4I(x_dim))\nR = sparse(1e-2I(u_dim))\nQN = sparse(1e2I(x_dim))","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Define  beginalign Z = beginbmatrix      x_1  x_2  cdots  x_N \n    u_1  u_2  cdots  u_N  endbmatrix \nRightarrow vecZ = beginbmatrix x_1  u_1  x_2  u_2  vdots  x_N  u_N endbmatrix endalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"and drop the first state (known) and last control (not used), z = vecZtextlength(x_1)textend-textlength(u_N)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"z_dim = (N-2) * (x_dim + u_dim) + u_dim + x_dim","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Write the cost function as J = tfrac12 z^T H z, where H = beginbmatrix         R_1  0  0   0 \n        0  Q_2  0  cdots  0 \n        0  0  R_2   0 \n         vdots   ddots  vdots \n        0  0  0  cdots  Q_N \n    endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"# Recall our shorthand for kron\nH = blockdiag(sparse(R), I(N-2) ⊗ blockdiag(sparse(Q), sparse(R)), sparse(QN))","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Write the dynamics constraint, Cz = d, where C = beginbmatrix     B_1  -I  0  0   0 \n    0  A_2  B_2  -I  cdots  0 \n    vdots  vdots  ddots  ddots  ddots  0 \n    0  0  cdots  A_N-1  B_N-1  -I endbmatrix qquad d = beginbmatrix     -A_1 x_1 \n    0 \n    0 \n    vdots \n    0 endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"C = I(N-1) ⊗ [B -I(x_dim)]\nfor k = 1:N-2\n    C[(k * x_dim) .+ (1:x_dim), (k * (x_dim + u_dim) - x_dim) .+ (1:x_dim)] = A\nend\nC","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"# Check the structure of C\nk = 6\n(\n    C[(k * x_dim) .+ (1:x_dim), (k * (x_dim + u_dim) - x_dim) .+ (1:(2x_dim + u_dim))] \n    == [A B -I(x_dim)]\n)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"d = [-A * x1; zeros((N-2) * x_dim)];","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Putting it all together,  beginalign     min_z quad tfrac12 z^T H z \n    textstquad C z = d endalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Lagrangian:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"L(z lambda) = tfrac12 z^T H z + lambda^T (C z - d)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"KKT conditions:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"beginalign\n     nabla_z L = H z + C^T lambda overset= 0 \n     nabla_lambda L = Cz - d overset= 0 \nendalign","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Matrix form:","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Rightarrow beginbmatrix H  C^T  C  0 endbmatrix \n    beginbmatrix z  lambda endbmatrix \n    = beginbmatrix 0  d endbmatrix","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Quick check: How many iterations will this take to solve?","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"P = [H C'; C zeros(size(C, 1), size(C, 1))]\n\nres_qp = P \\ [zeros(z_dim); d]\n\n# Extract the minimizer\nz_minimizer = res_qp[1:z_dim]\nu_minimizer = z_minimizer[1:x_dim + u_dim:end];","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"fig, ax = series(simulate_dlti(u_minimizer, A, B, x1), labels=[\"q\", \"q̇\"])\naxislegend(ax)\nfig","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"stairs(u_minimizer)","category":"page"},{"location":"7_trajectory_optimization/","page":"Trajectory Optimization","title":"Trajectory Optimization","text":"Quick check: What about the temporal structure?","category":"page"},{"location":"1_intro_to_julia/#Intro-to-Julia","page":"Intro to Julia","title":"Intro to Julia","text":"","category":"section"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Julia Intro for QNumerics Summer School by Raye Kimmerer.","category":"page"},{"location":"1_intro_to_julia/#Other-resources","page":"Intro to Julia","title":"Other resources","text":"","category":"section"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Julia cheat sheet","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Modern Julia Workflows","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Performant Serial Julia","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"What scientists must know about hardware to write fast code","category":"page"},{"location":"1_intro_to_julia/#Linear-Algebra","page":"Intro to Julia","title":"Linear Algebra","text":"","category":"section"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"LinearAlgebra docs","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"using LinearAlgebra\nusing SparseArrays\nusing InteractiveUtils\n\nA = rand(100,100)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Transpose and other operations are non-allocating, and instead create a wrapper of the original array. This prevents unecessary allocation and allows more  opportunity to dispatch on array types.","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"B = transpose(A)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"C = copy(B)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"When we copy the array it allocates and is no longer a wrapper","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Diagonal(A)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"subtypes(LinearAlgebra.Factorization)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"issymmetric(A*A')","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"How do we communicate this to the dispatch system?","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"D = Symmetric(A*A')","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Now we can dispatch on the fact that this matrix is symmetric, allowing us to select more efficient algorithms for this case.","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"Symmetric(A)","category":"page"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"This is 'casting' to a symmetric matrix, it will happily create a symmetric matrix out of a non-symmetric one.","category":"page"},{"location":"1_intro_to_julia/#Sparse-Arrays","page":"Intro to Julia","title":"Sparse Arrays","text":"","category":"section"},{"location":"1_intro_to_julia/","page":"Intro to Julia","title":"Intro to Julia","text":"A = sprand(100,100,0.1)","category":"page"},{"location":"creation/#Creating-this-package","page":"Creating this package","title":"Creating this package","text":"","category":"section"},{"location":"creation/#PkgTemplates","page":"Creating this package","title":"PkgTemplates","text":"","category":"section"},{"location":"creation/","page":"Creating this package","title":"Creating this package","text":"Template:\n  authors: [\"Jeffrey Wack <jeffwack111@gmail.com> and contributors\"]\n  dir: \"~/.julia/dev\"\n  host: \"github.com\"\n  julia: v\"1.11.0\"\n  user: \"jeffwack\"\n  plugins:\n    Citation:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/CITATION.bib\"\n      readme: true\n    Dependabot:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/github/dependabot.yml\"\n    Documenter:\n      assets: String[]\n      logo: Logo(nothing, nothing)\n      makedocs_kwargs: Dict{Symbol, Any}()\n      canonical_url: PkgTemplates.github_pages_url\n      make_jl: \"~/.julia/packages/PkgTemplates/5mBnk/templates/docs/make.jlt\"\n      index_md: \"~/.julia/packages/PkgTemplates/5mBnk/templates/docs/src/index.md\"\n      devbranch: nothing\n      edit_link: :devbranch\n    Git:\n      ignore: String[]\n      name: nothing\n      email: \"jeffwack111@gmail.com\"\n      branch: \"main\"\n      ssh: false\n      jl: true\n      manifest: false\n      gpgsign: false\n    GitHubActions:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/github/workflows/CI.yml\"\n      destination: \"CI.yml\"\n      linux: true\n      osx: true\n      windows: true\n      x64: true\n      x86: true\n      coverage: true\n      extra_versions: [\"1.6\", \"1.11\", \"pre\"]\n    License:\n      path: \"~/.julia/packages/PkgTemplates/5mBnk/templates/licenses/MIT\"\n      destination: \"LICENSE\"\n    ProjectFile:\n      version: v\"1.0.0-DEV\"\n    Readme:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/README.md\"\n      destination: \"README.md\"\n      inline_badges: false\n      badge_order: DataType[Documenter{GitHubActions}, Documenter{GitLabCI}, Documenter{TravisCI}, GitHubActions, GitLabCI, TravisCI, AppVeyor, DroneCI, CirrusCI, Codecov, Coveralls, BlueStyleBadge, ColPracBadge, PkgEvalBadge]\n      badge_off: DataType[]\n    SrcDir:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/src/module.jlt\"\n    TagBot:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/github/workflows/TagBot.yml\"\n      destination: \"TagBot.yml\"\n      trigger: \"JuliaTagBot\"\n      token: Secret(\"GITHUB_TOKEN\")\n      ssh: Secret(\"DOCUMENTER_KEY\")\n      ssh_password: nothing\n      changelog: nothing\n      changelog_ignore: nothing\n      gpg: nothing\n      gpg_password: nothing\n      registry: nothing\n      branches: nothing\n      dispatch: nothing\n      dispatch_delay: nothing\n    Tests:\n      file: \"~/.julia/packages/PkgTemplates/5mBnk/templates/test/runtests.jlt\"\n      project: false\n      aqua: false\n      aqua_kwargs: NamedTuple()\n      jet: false","category":"page"},{"location":"creation/#Github-Pages","page":"Creating this package","title":"Github Pages","text":"","category":"section"},{"location":"creation/","page":"Creating this package","title":"Creating this package","text":"Go to repository settings, deploy from a branch, gh-pages /root.","category":"page"},{"location":"creation/","page":"Creating this package","title":"Creating this package","text":"Now the docs appear on the dev branch. Clicking on the stable badge leads to a 404 error. ","category":"page"},{"location":"creation/#First-release","page":"Creating this package","title":"First release","text":"","category":"section"},{"location":"creation/","page":"Creating this package","title":"Creating this package","text":"I created a release, v1.0, on GitHub. This triggered the CI workflow, which includes a 'Documentation' action. Now the documentation appears on both badges, stable and dev. I then pushed changes to the documentation, which appeared on the dev docs but not stable. From this I conclude the stable docs only update after a release. ","category":"page"},{"location":"6_grape_demos/#GRAPE-Demos","page":"GRAPE Demos","title":"GRAPE Demos","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"using Piccolo\nusing Optim\nusing LinearAlgebra\nusing SparseArrays\nusing CairoMakie\n\n# useful\nconst ⊗ = kron","category":"page"},{"location":"6_grape_demos/#Goals","page":"GRAPE Demos","title":"Goals","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Learn the quantum isomorphisms that map variables to real-valued state vectors\nStudy how gradient descent and Newton's method can be used to optimize quantum controls.","category":"page"},{"location":"6_grape_demos/#I.-Isomorphisms","page":"GRAPE Demos","title":"I. Isomorphisms","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Piccolo isomorphisms","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"The standard quantum states are kets, psirangle, and Unitaries, U.\nOpen quantum system require density matrices, rho, and quantum channels, Phi.\nStandard quantum states have an open system counterpart,","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"beginalign\n    textclosed longrightarrow textopen   hline\n    psirangle longrightarrow psirangle langle psi  \n    U longrightarrow U cdot U^dagger \nendalign","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"🚧 ⚠️ If you are seeing a lot of boxes like Ũ⃗, it is very useful to have the JuliaMono fonts for Piccolo. Install and change the default font family.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Ok, so it's not technically a wavefunction\nψ = [1; 2] + im * [3; 4]\n\nψ̃ = ket_to_iso(ψ)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"iso_to_ket(ψ̃)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# We often need to convert a complex matrix U to a real vector, Ũ⃗. \nU = [1 5; 2 6] + im * [3 7; 4 8]","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Remember what you learned about Julia arrays! Why would I write the matrix this way?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Ũ⃗ = operator_to_iso_vec(U)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"iso_vec_to_operator(Ũ⃗)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Physics check: What's an efficiency that we might be able to leverage when storing rho that you don't see here?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Warning: The isomorphism `density_to_iso_vec` is not the same as `operator_to_iso_vec`.\nρ = [1 2; 3 4] + im * [5 6; 7 8]\nρ̃⃗ = density_to_iso_vec(ρ)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Exercise ","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Just how big are these vectors for a single qubit state? A two qubit state? \nWhat about quantum channels?","category":"page"},{"location":"6_grape_demos/#II.-Quantum-dynamics","page":"GRAPE Demos","title":"II. Quantum dynamics","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quantum systems","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"First up, we are going to look at some dynamics convenience functions in Piccolo.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Let's flip a qubit from the ground state to the excited state.\nIntroduce the isomorphisms that make quantum dynamics real-valued.  \nUse PiccoloQuantumObjects to make a quantum system.\nUse a rollout to integrate the quantum system forward in time.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"H(u(t)) = underbraceu_1(t) XI + u_2(t) YI_textqubit 1 \n    + underbraceu_3(t) IX + u_4(t) IY_textqubit 2 + underbraceu_5(t) XX_textcoupling","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"H_drives = [\n    PAULIS.X ⊗ PAULIS.I,\n    PAULIS.Y ⊗ PAULIS.I,\n    PAULIS.I ⊗ PAULIS.X,\n    PAULIS.I ⊗ PAULIS.Y,\n    PAULIS.X ⊗ PAULIS.X\n]\n\nsystem = QuantumSystem(H_drives)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quantum systems contain the operators we need, including the real valued versions.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"get_drift(system)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quick check: What do we expect to see?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"get_drives(system)[1]","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"system.H(randn(system.n_drives))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quick check: How big will this operator be?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"system.G(randn(system.n_drives))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"We can use a system to perform a rollout.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Timing information (e.g. 20 ns superconducting qubit gate)\nT = 40\nΔt = 0.5\ntimesteps = fill(Δt, T)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Controls\ncontrols = randn(system.n_drives, T + 1);","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"unitary_rollout(controls, timesteps, system)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Entangling gate\nU_goal = GATES.CX\n\n# How'd we do?\nprintln(\"ℱ = \", unitary_rollout_fidelity(U_goal, controls, timesteps, system))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"We have all the pieces we need to solve!","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Let's put Piccolo to work.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# Piccolo (we'll learn more about this later)\nprob = UnitarySmoothPulseProblem(system, U_goal, T, Δt);","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# save these initial controls for later\na_init = prob.trajectory.a\nplot(prob.trajectory, :a)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"solve!(\n    prob, \n    max_iter=20, print_level=1, verbose=false, options=IpoptOptions(eval_hessian=false)\n)\n\nℱ = unitary_rollout_fidelity(prob.trajectory, system)\n\nprintln(\"The fidelity is \", ℱ)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"a_final = prob.trajectory.a\nplot(prob.trajectory, :a)","category":"page"},{"location":"6_grape_demos/#III.-GRAPE","page":"GRAPE Demos","title":"III. GRAPE","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"The GRAPE algorithm comes from NMR in 2004, and there is a Julia version. We'll reproduce GRAPE in this example.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# We work with timesteps between knot points\ntimesteps = fill(Δt, T)\n\n# Let's use our previous function to compute the fidelity\nGRAPE(controls) = abs(1 - unitary_rollout_fidelity(U_goal, controls, timesteps, system))","category":"page"},{"location":"6_grape_demos/#Automatic-differentiation","page":"GRAPE Demos","title":"Automatic differentiation","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"It's quick to test! Compare different algorithms, e.g., Newton(), GradientDescent(), LBFGS()\nIf you switch from gradient descent to a quasi-Newton method, you get to write another paper.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"result_GRAPE = optimize(GRAPE, collect(a_init), LBFGS())","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"a_GRAPE = Optim.minimizer(result_GRAPE)\nprintln(\"The fidelity is \", unitary_rollout_fidelity(U_goal, a_GRAPE, timesteps, system))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"What do we think we'll see here?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"series(cumsum(timesteps), a_GRAPE)","category":"page"},{"location":"6_grape_demos/#Analytic-gradients","page":"GRAPE Demos","title":"Analytic gradients","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Calculus practice","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"We can combine forward and backward rollouts to compute the gradients,","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"beginalign\n    fracpartial U(T)partial u_k(t) = U(T t) (-i H_k Delta t) U(t) \n   Rightarrow langlepsi_textgoal  fracpartial U(T)partial u_k(t) psi_textinitrangle = -i Delta t langlepsi_textgoal^textbwd(t)  H_k psi_textinit^textfwd(t) rangle\nendalign","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Exercise","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Implement gradient descent using the analytic gradients.\nSometimes, there are insights you can only get by opening up the black box, e.g. d-GRAPE.","category":"page"},{"location":"6_grape_demos/#IV.-Function-Spaces","page":"GRAPE Demos","title":"IV. Function Spaces","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Pick a function basis for the controls and optimize the coefficients. Some choices are trig functions or Slepians.\nOur optimization parameters are now coefficients of the basis,","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"u(t) = u_0 + sum_j=1^n c_j a_j(t)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"The modes a_j(t) stay fixed, and the coefficients c_j are optimized.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"# First n = 5 entries in a Fourier series, including the constant term\nn = 5\nfourier_series = [cos.(π * j * (0:T-1) / T .- π/2) for j in 0:n-1]\n\nfunction get_controls(coefficients)\n    a(c) = sum(cⱼ * aⱼ for (cⱼ, aⱼ) in zip(c, fourier_series))\n    return stack([a(c) for c in eachrow(coefficients)], dims=1)\nend\n\nfunction GRAFS(coefficients)\n    controls = get_controls(coefficients)\n    return abs(1 - unitary_rollout_fidelity(U_goal, controls, timesteps, system))\nend","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"c_init = rand(system.n_drives, n)\nresult_GRAFS = optimize(GRAFS, c_init, LBFGS())","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"a_GRAFS = Optim.minimizer(result_GRAFS)\nprintln(\"The fidelity is \", 1 - unitary_rollout_fidelity(U_goal, a_GRAFS, timesteps, system))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"series(cumsum(timesteps), get_controls(a_GRAFS))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"These shapes are a lot nicer! But performance depends a lot on the expressivity and initial condition.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"c_init = randn(system.n_drives, n)\nresult_GRAFS_2 = optimize(GRAFS, c_init, LBFGS())","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"a_GRAFS_2 = Optim.minimizer(result_GRAFS_2)\nprintln(\"The fidelity is \", 1 - unitary_rollout_fidelity(U_goal, a_GRAFS_2, timesteps, system))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"f = Figure()\nax = Axis(f[1,1])\nseries!(ax, cumsum(timesteps), get_controls(a_GRAFS))\nax = Axis(f[2,1])\nseries!(ax, cumsum(timesteps), get_controls(a_GRAFS_2))\nf","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Exercise: A filtering approach","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Pass the controls through a spectral filter: Look up Slepians and consider how to bound the bandwidth by choice of basis.\nHow might we shape the bandwidth of the controls? (Remember, we can just rely on automatic differentiation!)","category":"page"},{"location":"6_grape_demos/#V.-States-in-costs","page":"GRAPE Demos","title":"V. States in costs","text":"","category":"section"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Exercise:","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Let's switch to a transmon, which has more than two levels and can be leaky.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"H(u(t)) = tfrac12 eta a^dagger a^dagger a a + u_1(t) (a + a^dagger) - i u_2(t) (a - a^dagger)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"The optimizer can exploit the higher levels!\nAdd a leakage penalty to a guard state. Notice that working with states can be awkward.","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"T = 40\nΔt = 0.25\ntimesteps = fill(Δt, T)\n\nfunction Transmon(n)\n    a = annihilate(n)\n    x = a + a'\n    p = -im * (a - a')\n    η = 0.1\n    return QuantumSystem(1/2 * a'a'a*a, [x, p])\nend\n\ntransmon_2 = Transmon(2)\ntransmon_4 = Transmon(4)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"function TransmonGRAFS(\n    goal::AbstractPiccoloOperator, coefficients, timesteps, sys::AbstractQuantumSystem\n)\n    controls = get_controls(coefficients)\n    return abs(1 - unitary_rollout_fidelity(goal, controls, timesteps, sys))\nend","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quick aside: Embedded operators","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"U_emb(n) = EmbeddedOperator(GATES.X, 1:2, n)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"U_emb(4).operator","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"unembed(U_emb(4))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"sys2, U2 = Transmon(2), U_emb(2)\nc_init = randn(sys2.n_drives, n)\nresult_GRAFS_3 = optimize(a -> TransmonGRAFS(U2, a, timesteps, sys2), c_init, LBFGS())","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"a_GRAFS_3 = get_controls(Optim.minimizer(result_GRAFS_3))\nprintln(\"The fidelity is \", unitary_rollout_fidelity(U2, a_GRAFS_3, timesteps, sys2))","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Quick check: What might happen now?","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"println(\n    \"The fidelity is \", unitary_rollout_fidelity(U_emb(4), a_GRAFS_3, timesteps, Transmon(4))\n)","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"TODO: ","category":"page"},{"location":"6_grape_demos/","page":"GRAPE Demos","title":"GRAPE Demos","text":"Add an L2 penalty to states that are not in the computational basis.\nUse a modified GRAPE cost to penalize leakage while maintaining fidelity.\nStudy how leakage and fidelity change with the penalty.\nStudy how the anharmonicity η affects leakage.","category":"page"},{"location":"9_quantum_trajectory_optimization/#Quantum-Trajectory-Optimization-Lecture-3","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization - Lecture 3","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"using Piccolo\nusing LinearAlgebra\nusing CairoMakie\nusing QuantumToolbox\nusing SparseArrays\n\nconst ⊗ = kron","category":"page"},{"location":"9_quantum_trajectory_optimization/#I.-Rotations","page":"Quantum Trajectory Optimization","title":"I. Rotations","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/#Goals","page":"Quantum Trajectory Optimization","title":"Goals","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Geodesics\nControllability of LTI systems\nDynamical Lie algebras and reachability","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Comparing initialization and optimization when restricted to a feasible manifold, and how warm starts are enabled by direct control.","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"(Image: Initialization comparison between direct and indirect optimization.)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"U_goal = PAULIS.X\nT = 40\nΔt = 0.1\n\n# U_goal = exp(-im * H_eff * T * Δt)\nH_eff = im * log(U_goal / T / Δt)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Exercise","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"What happens if there is a drift operator? H(t) = Delta omega Z + u(t) X.\nBonus: What about for an Embedded operator?","category":"page"},{"location":"9_quantum_trajectory_optimization/#Controllability","page":"Quantum Trajectory Optimization","title":"Controllability","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Quick check: What happens when we kick a system x_n+1 = A x_n + B u_n?","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"mathcalC = beginbmatrix\n    B  A B  A^2 B  cdots  A^n-1 B\nendbmatrix","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Quick check: Why did we stop at n-1?","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Example","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Test on a linear system in 2D. Recall our F = ma system.","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"function continuous_to_discrete(A, B, h)\n    # Construct augmented matrix for matrix exponential\n    augmented_matrix = [\n        A B; \n        zeros(size(B, 2), size(A, 1)) zeros(size(B, 2), size(B, 2))\n    ]\n\n    # Compute matrix exponential\n    exp_matrix = exp(augmented_matrix * h)\n\n    # Extract discrete LTI system matrices\n    A_h = exp_matrix[1:size(A, 1), 1:size(A, 2)]\n    B_h = exp_matrix[1:size(A, 1), size(A, 2)+1:end]\n\n    return A_h, B_h\nend\n\n# Extract discrete LTI system matrices\nA_cts = [0.0 1.0; -1.0 -0.1]\nB_cts = [0.0; 1.0]\nh = 0.1  # Time step\nA, B = continuous_to_discrete(A_cts, B_cts, h)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Let's create a 2D state.","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"z = beginbmatrix x  dotx  y  doty endbmatrix","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Axy = I(2) ⊗ A\nBxy = [B zeros(2); zeros(2) B]\n\nC = hcat([Axy^n * Bxy for n in 0:size(Axy, 1)-1]...)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"rank(C)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Axy = I(2) ⊗ A\n\n# Directly move the X particle only\nBxy = [[1; 0] zeros(2); [0; 1] zeros(2)]\n\nC = hcat([Axy^n * Bxy for n in 0:size(Axy, 1)-1]...)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"rank(C)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"What about quantum systems? They are nonlinear.","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"BCH","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"e^X e^Y = e^X + Y + tfrac12 X Y + tfrac112 (X X Y + Y Y X)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Collect commutators, forming the Dynamical Lie algebra.\nQuick check: How can we test for linear dependence?","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"# Linearly dependent: QR decomposition has a zero on diagonal \nH_drives = [PAULIS.X, PAULIS.Y]\n# H_drives = [PAULIS.X, PAULIS.X]\n\nM = stack(vec.(H_drives))\nqr(M).R","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Quick check: What about systems with drift?","category":"page"},{"location":"9_quantum_trajectory_optimization/#II.-Demos","page":"Quantum Trajectory Optimization","title":"II. Demos","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Bloch sphere","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Δ = 0.2\nqubit = QuantumSystem(Δ * PAULIS.Z, [PAULIS.X, PAULIS.Y])\nψ0 = ket_from_string(\"e+g\", [2])\nψT = ket_from_bitstring(\"0\")\nT = 40\nΔt = 0.1\nprob = QuantumStateSmoothPulseProblem(qubit, ψ0, ψT, T, Δt)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_bloch(prob.trajectory)\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"plot(prob.trajectory, :a)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"solve!(prob, max_iter=30, options=IpoptOptions(eval_hessian=true))","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_bloch(prob.trajectory)\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"plot(prob.trajectory, :a)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"CZ gate","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"H(t) = sum_j tfraceta2 a_j^dagger a_j^dagger a_j a_j + Delta(t) (a_1^dagger a_1) + g(t) (a_1^dagger a_2 + a_1 a_2^dagger)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"n_levels = 2\na = lift_operator(annihilate(n_levels), 1, 2)\nb = lift_operator(annihilate(n_levels), 2, 2)\nη = -0.3\n\nH_drift = η/2 * (a'a'*a*a + b'b'*b*b)\nH_drives = [a'a', (a'b + a*b')]\ntransmons = QuantumSystem(H_drift, H_drives)\n\nU_goal = EmbeddedOperator(\n    GATES.CZ, \n    get_subspace_indices([1:2, 1:2], [n_levels, n_levels]), \n    [n_levels, n_levels]\n)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"commutator(A, B) = A * B - B * A","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"A = H_drives[1]\nB = H_drives[2]\ncommutator(A, B) |> sparse","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"try\n    is_reachable(U_goal, transmons)\ncatch e\n    println(e)\nend","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Continuous-variable quantum computing","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"H(t) = Omega(t) a^dagger + Omega(t) a + kappa(t) a^2 + kappa^*(t) (a^dagger)^2","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"n_levels = 5\n\na = annihilate(n_levels)\nX = a + a'\nY = -im * (a - a')\nX2 = a^2 + (a')^2\nY2 = -im * (a^2 - (a')^2)\n\nΩ = 1.0\nκ = 0.1\n\nsys = QuantumSystem([X, Y, X2, Y2])\n\n# Displacement and squeezing operators\nfunction displacement(α)\n    return exp(α * a' - conj(α) * a)\nend\n\nfunction squeezing(r)\n    return exp((r / 2) * (a^2 - (a')^2))\nend\n\n# Initial states\nψ0 = I(n_levels)[:, 1] .+ 0.0im\nψα = displacement(im * 1.5) * ψ0;\nψs = squeezing(0.5) * displacement(0.5 + 0.5im) * ψ0;","category":"page"},{"location":"9_quantum_trajectory_optimization/#Coherent-state","page":"Quantum Trajectory Optimization","title":"Coherent state","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"T = 40\nΔt = 0.2\nprob = QuantumStateSmoothPulseProblem(sys, ψ0, ψα, T, Δt, dda_bound=0.1)\nsolve!(prob, max_iter=30, options=IpoptOptions(eval_hessian=true))","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"rollout_fidelity(prob.trajectory, sys)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_wigner(prob.trajectory, 1)\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_wigner(prob.trajectory, prob.trajectory.T)\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_wigner(QuantumObject(ψα))\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"plot(\n    prob.trajectory, [:a],\n    transformations = [:ψ̃ => ψ̃ -> abs2.(iso_to_ket(ψ̃)),],\n    use_autolimits=true,\n    transformation_titles = [\"Population\"],\n)","category":"page"},{"location":"9_quantum_trajectory_optimization/#Minimum-Time","page":"Quantum Trajectory Optimization","title":"Minimum Time","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"min_prob = QuantumStateMinimumTimeProblem(prob, ψα)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"solve!(min_prob, max_iter=30)","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"fig, = plot_wigner(min_prob.trajectory, min_prob.trajectory.T)\nfig","category":"page"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"plot(\n    min_prob.trajectory, [:a],\n    transformations = [:ψ̃ => ψ̃ -> abs2.(iso_to_ket(ψ̃)),],\n    use_autolimits=true,\n    transformation_titles = [\"Population\"],\n)","category":"page"},{"location":"9_quantum_trajectory_optimization/#Squeezed-states","page":"Quantum Trajectory Optimization","title":"Squeezed states","text":"","category":"section"},{"location":"9_quantum_trajectory_optimization/","page":"Quantum Trajectory Optimization","title":"Quantum Trajectory Optimization","text":"Further exercises and explorations with squeezed states can be implemented here.","category":"page"},{"location":"#QNumerics2025","page":"Home","title":"QNumerics2025","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Created at QNumerics2025.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
