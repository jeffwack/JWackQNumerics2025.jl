<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Trajectory Optimization · QNumerics2025.jl</title><meta name="title" content="Trajectory Optimization · QNumerics2025.jl"/><meta property="og:title" content="Trajectory Optimization · QNumerics2025.jl"/><meta property="twitter:title" content="Trajectory Optimization · QNumerics2025.jl"/><meta name="description" content="Documentation for QNumerics2025.jl."/><meta property="og:description" content="Documentation for QNumerics2025.jl."/><meta property="twitter:description" content="Documentation for QNumerics2025.jl."/><meta property="og:url" content="https://jeffwack.github.io/QNumerics2025.jl/7_trajectory_optimization/"/><meta property="twitter:url" content="https://jeffwack.github.io/QNumerics2025.jl/7_trajectory_optimization/"/><link rel="canonical" href="https://jeffwack.github.io/QNumerics2025.jl/7_trajectory_optimization/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">QNumerics2025.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../creation/">Creating this package</a></li><li><a class="tocitem" href="../1_intro_to_julia/">Intro to Julia</a></li><li><a class="tocitem" href="../2_introduction_to_state_vector_simulation/">Introduction to State Vector Simulation</a></li><li><a class="tocitem" href="../3_dynamics_and_quantumoptics/">Dynamics and QuantumOptics.jl</a></li><li><a class="tocitem" href="../4_quantum_trajectories/">Quantum Trajectories</a></li><li><a class="tocitem" href="../5_optimization_methods/">Optimization Methods</a></li><li><a class="tocitem" href="../6_grape_demos/">GRAPE Demos</a></li><li class="is-active"><a class="tocitem" href>Trajectory Optimization</a><ul class="internal"><li><a class="tocitem" href="#Getting-started"><span>Getting started</span></a></li><li><a class="tocitem" href="#I.-Trajectory-optimization"><span>I. Trajectory optimization</span></a></li><li><a class="tocitem" href="#II.-Linear-Quadratic-Regulator"><span>II. Linear Quadratic Regulator</span></a></li></ul></li><li><a class="tocitem" href="../8_nonlinear_trajectory_optimization/">Nonlinear Trajectory Optimization</a></li><li><a class="tocitem" href="../9_quantum_trajectory_optimization/">Quantum Trajectory Optimization</a></li><li><a class="tocitem" href="../10_clifford/">Clifford</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Trajectory Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Trajectory Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/jeffwack/QNumerics2025.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/jeffwack/QNumerics2025.jl/blob/main/docs/src/7_trajectory_optimization.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Trajectory-Optimization-Lecture-2"><a class="docs-heading-anchor" href="#Trajectory-Optimization-Lecture-2">Trajectory Optimization - Lecture 2</a><a id="Trajectory-Optimization-Lecture-2-1"></a><a class="docs-heading-anchor-permalink" href="#Trajectory-Optimization-Lecture-2" title="Permalink"></a></h1><pre><code class="language-julia hljs">using Optim
using LinearAlgebra
using SparseArrays
using CairoMakie
using Piccolo

# let&#39;s define a shorthand for kron
const ⊗ = kron</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">kron (generic function with 61 methods)</code></pre><h2 id="Getting-started"><a class="docs-heading-anchor" href="#Getting-started">Getting started</a><a id="Getting-started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-started" title="Permalink"></a></h2><h3 id="Review"><a class="docs-heading-anchor" href="#Review">Review</a><a id="Review-1"></a><a class="docs-heading-anchor-permalink" href="#Review" title="Permalink"></a></h3><ul><li>Gradient descent</li><li>Newton&#39;s method and KKT conditions</li><li>Regularization</li><li>Newton approximations</li><li>Line search</li></ul><h3 id="Goals"><a class="docs-heading-anchor" href="#Goals">Goals</a><a id="Goals-1"></a><a class="docs-heading-anchor-permalink" href="#Goals" title="Permalink"></a></h3><ul><li>Introduce trajectory optimization</li><li>Solve the LQR problem three ways</li><li>Describe nonlinear trajectory optimization</li></ul><h2 id="I.-Trajectory-optimization"><a class="docs-heading-anchor" href="#I.-Trajectory-optimization">I. Trajectory optimization</a><a id="I.-Trajectory-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#I.-Trajectory-optimization" title="Permalink"></a></h2><ul><li>The solution is a definite <em>trajectory</em>, not a feedback policy.</li></ul><p class="math-container">\[\begin{align}
\min_{x_{1:N}, u_{1:N}} &amp;\quad J(x_{1:N}, u_{1:N}) = \sum_{n=1}^N \ell_n(x_n, u_n) + \ell_N(x_N, u_N) \\
\text{s.t.} &amp;\quad x_{n+1} = f(x_n, u_n, n)
\end{align}\]</p><h3 id="Named-Trajectories"><a class="docs-heading-anchor" href="#Named-Trajectories">Named Trajectories</a><a id="Named-Trajectories-1"></a><a class="docs-heading-anchor-permalink" href="#Named-Trajectories" title="Permalink"></a></h3><p><strong>Terminology</strong></p><ul><li><em>Snapshot matrix</em>, <span>$Z = \begin{bmatrix} | &amp; | &amp; &amp; | \\ z_1 &amp; z_2 &amp; &amp; z_T \\ | &amp; | &amp; &amp; | \end{bmatrix}$</span></li><li><em>Knot point</em>, <span>$z_1 = \begin{bmatrix} x_1 \\ u_1 \end{bmatrix}$</span></li></ul><pre><code class="language-julia hljs">N = 10 # Number of knot points
traj = rand(NamedTrajectory, N)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">T = 10, (x = 1:3, u = 4:5, → Δt = 6:6)</code></pre><pre><code class="language-julia hljs">traj.x</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×10 view(reshape(view(::Vector{Float64}, :), 6, 10), 1:3, :) with eltype Float64:
  0.457533  -2.35182    0.660083  -0.856307   …  -1.35003  0.941149  1.75569
  1.69218    0.409696   0.766585   0.0217461     -1.2624   1.09609   0.555132
 -0.704936  -0.0920414  0.351501   0.58511        1.05494  0.186944  0.186521</code></pre><pre><code class="language-julia hljs">traj.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×10 view(reshape(view(::Vector{Float64}, :), 6, 10), 4:5, :) with eltype Float64:
 1.24957  1.44903   -0.554347  -0.66381  …  0.740205  -0.492164  -0.433807
 0.38033  0.291519  -0.638417  -2.01442     1.78874   -0.143572   0.263034</code></pre><pre><code class="language-julia hljs">plot(traj, :x)</code></pre><img src="26a9f47b.png" alt="Example block output"/><h2 id="II.-Linear-Quadratic-Regulator"><a class="docs-heading-anchor" href="#II.-Linear-Quadratic-Regulator">II. Linear Quadratic Regulator</a><a id="II.-Linear-Quadratic-Regulator-1"></a><a class="docs-heading-anchor-permalink" href="#II.-Linear-Quadratic-Regulator" title="Permalink"></a></h2><ul><li>LQR is the &quot;simple harmonic oscillator&quot; of control</li></ul><p class="math-container">\[\begin{align}
\min_{x_{1:N}, u_{1:N{-}1}} &amp;\quad J = \sum_{n=1}^{N-1} \tfrac{1}{2} x_n^T Q_n x_n + \tfrac{1}{2} u_n^T R_n u_n + \tfrac{1}{2} x_N^T Q_N x_N \\
\text{s.t.} &amp;\quad x_{n+1} = A_n x_n + B_n u_n \\
&amp;\quad Q_n \succeq 0,\, R_n \succ 0
\end{align}\]</p><ul><li>Quick check: Why does <span>$R$</span> need to be positive definite?</li></ul><h3 id="Linear-systems"><a class="docs-heading-anchor" href="#Linear-systems">Linear systems</a><a id="Linear-systems-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-systems" title="Permalink"></a></h3><h4 id="Zero-order-hold"><a class="docs-heading-anchor" href="#Zero-order-hold">Zero-order hold</a><a id="Zero-order-hold-1"></a><a class="docs-heading-anchor-permalink" href="#Zero-order-hold" title="Permalink"></a></h4><ul><li>Zero-order hold can be used to convert continuous, linear, time-invariant (LTI) systems to discrete LTI systems.</li></ul><p class="math-container">\[\begin{align}
\dot{x}(t) &amp;= A x(t) + B u(t)  \\
\overset{h}{\longrightarrow} x(t+h) &amp;= A_h x(t) + B_h u(t) \\
&amp;= \left( \sum_{n\ge0} \tfrac{1}{n!} A^n h^n \right) x + \left( \sum_{n\ge1} \tfrac{1}{n!} A^{n-1} B h^n \right) u \\
&amp;\approx (I + h A) x + h B u
\end{align}\]</p><ul><li>Matrix exponential trick:</li></ul><p class="math-container">\[\exp\left(\begin{bmatrix} A &amp; B \\ 0 &amp; 0 \end{bmatrix} h \right)
= \begin{bmatrix} A_h &amp; B_h \\ 0 &amp; I \end{bmatrix}\]</p><pre><code class="language-julia hljs"># Define continuous LTI system matrices
A = [0.0 1.0; -1.0 -0.1]
B = [0.0; 1.0]
h = 0.1  # Time step

function continuous_to_discrete(A, B, h)
    # Construct augmented matrix for matrix exponential
    augmented_matrix = [
        A B;
        zeros(size(B, 2), size(A, 1)) zeros(size(B, 2), size(B, 2))
    ]

    # Compute matrix exponential
    exp_matrix = exp(augmented_matrix * h)

    # Extract discrete LTI system matrices
    A_h = exp_matrix[1:size(A, 1), 1:size(A, 2)]
    B_h = exp_matrix[1:size(A, 1), size(A, 2)+1:end]

    return A_h, B_h
end

# Extract discrete LTI system matrices
A_h, B_h = continuous_to_discrete(A, B, h);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.9950207737420776 0.09933590957864684; -0.09933590957864684 0.9850871827842128], [0.004979226257922404; 0.09933590957864684;;])</code></pre><pre><code class="language-julia hljs">A_h</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
  0.995021   0.0993359
 -0.0993359  0.985087</code></pre><pre><code class="language-julia hljs">I + A * h</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
  1.0  0.1
 -0.1  0.99</code></pre><pre><code class="language-julia hljs">B_h</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×1 Matrix{Float64}:
 0.004979226257922404
 0.09933590957864684</code></pre><pre><code class="language-julia hljs">B * h</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 0.0
 0.1</code></pre><h4 id="Double-Integrator"><a class="docs-heading-anchor" href="#Double-Integrator">Double Integrator</a><a id="Double-Integrator-1"></a><a class="docs-heading-anchor-permalink" href="#Double-Integrator" title="Permalink"></a></h4><ul><li>Double integrator (Newton&#39;s second law, <span>$F = ma$</span>)</li></ul><p class="math-container">\[m \frac{d}{dt} \begin{bmatrix} q \\ \dot{q} \end{bmatrix} 
= \begin{bmatrix} 0 &amp; m \\ 0 &amp; 0 \end{bmatrix} \begin{bmatrix} q \\ \dot{q} \end{bmatrix}
+ \begin{bmatrix} 0 \\ u \end{bmatrix}\]</p><pre><code class="language-julia hljs">function double_integrator(m)
    A_c = [0.0 1.0; 0.0 0.0]
    B_c = [0.0; 1.0 / m]
    return A_c, B_c
end

# simulate a discrete LTI system
function simulate_dlti(u::AbstractMatrix, A, B, x1)
    N = size(u, 2) + 1
    x = zeros(size(A, 2), N)
    x[:, 1] = x1
    for k in 1:N-1
        x[:, k + 1] = A * x[:, k] + B * u[:, k]
    end
    return x
end

function simulate_dlti(u::AbstractVector, A, B, x1)
    simulate_dlti(reshape(u, 1, length(u)), A, B, x1)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">simulate_dlti (generic function with 2 methods)</code></pre><pre><code class="language-julia hljs">m = 2.0 # Mass
A_c , B_c = double_integrator(m)
h = 0.05  # Time step
A, B = continuous_to_discrete(A_c, B_c, h);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([1.0 0.05; 0.0 1.0], [0.0006250000000000001; 0.025;;])</code></pre><pre><code class="language-julia hljs">A ≈ I + A_c * h</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><pre><code class="language-julia hljs">B ≈ B_c * h + [h^2 / 2m; 0]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h3 id="Indirect-optimal-control:-Naive-way"><a class="docs-heading-anchor" href="#Indirect-optimal-control:-Naive-way">Indirect optimal control: Naive way</a><a id="Indirect-optimal-control:-Naive-way-1"></a><a class="docs-heading-anchor-permalink" href="#Indirect-optimal-control:-Naive-way" title="Permalink"></a></h3><ul><li><p>Indirect optimal control is also known as &quot;single shooting&quot;</p></li><li><p>The naive way is to perform gradient descent without any problem structure.</p></li></ul><p class="math-container">\[\min_{u_{1:N{-}1}} \quad J(u_{1:N{-}1}) = \sum_{n=1}^{N-1} \ell_n(x_n(u_{1:n{-}1}), u_n) + \ell_N(x_N(u_{1:N{-}1}), u_N)\]</p><ul><li>We will start with the double integrator and solve the LQR problem,</li></ul><p class="math-container">\[\begin{align}
\min_{u_{1:N{-}1}} &amp;\quad J(u_{1:{N{-}1}}) = \sum_{n=1}^{N-1} \tfrac{1}{2} x_n(u_{1:n{-}1})^T Q_n x_n(u_{1:n{-}1}) + \tfrac{1}{2} u_n^T R_n u_n + \tfrac{1}{2} x_N(u_{1:N{-}1})^T Q_N x_N(u_{1:N{-}1}) \\
\text{s.t.} &amp;\quad Q_n \succeq 0,\, R_n \succ 0
\end{align}\]</p><pre><code class="language-julia hljs">m = 0.1 # Mass
A_c, B_c = double_integrator(m)
h = 0.1  # Time step
A, B = continuous_to_discrete(A_c, B_c, h)
x1 = [1.0; 2.0]  # Initial state

Q = 1e-4I
R = 1e-1I
QN = 1e2I

function J(
    x::AbstractMatrix,
    u::AbstractVecOrMat;
    Q = 1e-2I,
    R = 1e-4I,
    QN = 1e2I
)
    u = isa(u, AbstractMatrix) ? u : reshape(u, 1, length(u))

    N = size(u, 2) + 1
    J = 0.0
    for n in 1:N-1
        xₙ = x[:, n]
        uₙ = u[:, n]
        J += 1/2 * (xₙ&#39; * Q * xₙ + uₙ&#39; * R * uₙ)
    end
    J += 1/2 * (x[:, N]&#39; * QN * x[:, N])
    return J
end

function J(u::AbstractVecOrMat; A=A, B=B, x1=x1, kwargs...)
    x = simulate_dlti(u, A, B, x1)
    return J(x, u; kwargs...)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">J (generic function with 2 methods)</code></pre><h4 id="Gradient-descent"><a class="docs-heading-anchor" href="#Gradient-descent">Gradient descent</a><a id="Gradient-descent-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-descent" title="Permalink"></a></h4><pre><code class="language-julia hljs">N = 40
u0 = randn(N - 1)
J(u0; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1097.8158832101492</code></pre><pre><code class="language-julia hljs">fig, ax = series(simulate_dlti(u0, A, B, x1), labels=[&quot;q&quot;, &quot;q̇&quot;])
axislegend(ax)
fig</code></pre><img src="e3abed71.png" alt="Example block output"/><pre><code class="language-julia hljs">res = optimize(u -&gt; J(u; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN), u0, GradientDescent(),
               Optim.Options(iterations=50))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"> * Status: failure (reached maximum number of iterations)

 * Candidate solution
    Final objective value:     1.641849e+00

 * Found with
    Algorithm:     Gradient Descent

 * Convergence measures
    |x - x&#39;|               = 2.27e-04 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 9.14e-05 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.47e-04 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 8.95e-05 ≰ 0.0e+00
    |g(x)|                 = 7.91e-01 ≰ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    50
    f(x) calls:    151
    ∇f(x) calls:   151
</code></pre><pre><code class="language-julia hljs">fig, ax = series(simulate_dlti(res.minimizer, A, B, x1), labels=[&quot;q&quot;, &quot;q̇&quot;])
axislegend(ax)
fig</code></pre><img src="f08d0338.png" alt="Example block output"/><pre><code class="language-julia hljs">stairs(res.minimizer)</code></pre><img src="8bf24118.png" alt="Example block output"/><h4 id="Newton&#39;s-method"><a class="docs-heading-anchor" href="#Newton&#39;s-method">Newton&#39;s method</a><a id="Newton&#39;s-method-1"></a><a class="docs-heading-anchor-permalink" href="#Newton&#39;s-method" title="Permalink"></a></h4><pre><code class="language-julia hljs">res_newton = optimize(u -&gt; J(u; A=A, B=B, x1=x1, Q=Q, R=R, QN=QN), u0, Newton(),
                     Optim.Options(iterations=20))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"> * Status: success

 * Candidate solution
    Final objective value:     3.418396e-02

 * Found with
    Algorithm:     Newton&#39;s Method

 * Convergence measures
    |x - x&#39;|               = 1.45e-03 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 5.44e-03 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 3.02e-07 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 8.83e-06 ≰ 0.0e+00
    |g(x)|                 = 6.88e-12 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    2
    f(x) calls:    7
    ∇f(x) calls:   7
    ∇²f(x) calls:  2
</code></pre><pre><code class="language-julia hljs">fig, ax = series(simulate_dlti(res_newton.minimizer, A, B, x1), labels=[&quot;q&quot;, &quot;q̇&quot;])
axislegend(ax)
fig</code></pre><img src="5d0c794b.png" alt="Example block output"/><pre><code class="language-julia hljs">stairs(res_newton.minimizer)</code></pre><img src="88974347.png" alt="Example block output"/><h3 id="Indirect-optimal-control:-Pontryagin"><a class="docs-heading-anchor" href="#Indirect-optimal-control:-Pontryagin">Indirect optimal control: Pontryagin</a><a id="Indirect-optimal-control:-Pontryagin-1"></a><a class="docs-heading-anchor-permalink" href="#Indirect-optimal-control:-Pontryagin" title="Permalink"></a></h3><p><strong>Tagline</strong></p><p>&quot;optimize, then discretize&quot;</p><p><strong>Ideas</strong></p><ul><li>We can do this in a smart way by using the temporal structure of the problem.</li></ul><p class="math-container">\[\begin{align}
\min_{x_{1:N}, u_{1:{N{-}1}}} &amp; \quad J(x_{1:N}, u_{1:{N{-}1}}) = \sum_{n=1}^{N-1} \tfrac{1}{2} x_n^T Q_n x_n + \tfrac{1}{2} u_n^T R_n u_n + \tfrac{1}{2} x_N^T Q_N x_N \\
\text{s.t.} &amp;\quad x_{n+1} = A_n x_n + B_n u_n \\
&amp;\quad Q_n \succeq 0,\, R_n \succ 0
\end{align}\]</p><ul><li>Lagrangian:</li></ul><p class="math-container">\[L(x_{1:N}, u_{1:{N{-}1}}, \lambda_{2:N}) = \sum_{n=1}^{N-1} \tfrac{1}{2} x_n^T Q_n x_n + \tfrac{1}{2} u_n^T R_n u_n + \lambda_{n+1}^T(A_n x_n + B_n u_n - x_{n+1}) + \tfrac{1}{2} x_N^T Q_N x_N\]</p><ul><li>KKT conditions:</li></ul><p class="math-container">\[\begin{align}
    \frac{\partial L}{\partial \lambda_n} &amp;= (A_n x_n + B_n u_n - x_{n+1})^T \overset{!}{=} 0 \\
    \frac{\partial L}{\partial x_n} &amp;= x_n^T Q_n + \lambda_{n+1}^T A_n - \lambda_{n}^T \overset{!}{=} 0 \\
    \frac{\partial L}{\partial x_N} &amp;= x_N^T Q_N - \lambda_{N}^T \overset{!}{=} 0 \\
    \frac{\partial L}{\partial u_n} &amp;= u_n^T R_n + \lambda_{n+1}^T B_n \overset{!}{=} 0
\end{align}\]</p><ul><li>Rewrite:</li></ul><p class="math-container">\[\begin{align}
    x_{n+1} &amp;= A_n x_n + B_n u_n \\
    \lambda_{n} &amp;= A_n^T \lambda_{n+1} + Q_n x_n \\
    \lambda_N &amp;= Q_N x_N \\
    u_n &amp;= -R_n^{-1} B_n^T \lambda_{n+1}
\end{align}\]</p><ul><li>There is a <em>forward</em> equation and a <em>backward</em> equation. This computation is <em>backpropagation</em> through time.</li><li>We inherit many of the same problems, e.g., vanishing / exploding gradients.</li></ul><pre><code class="language-julia hljs">N = 60
m = 1.0 # Mass
A_c, B_c = double_integrator(m)
h = 0.1  # Time step
A, B = continuous_to_discrete(A_c, B_c, h)
x1 = [1.0; 1.0]  # Initial state

Q = 1e-4I
R = 1e-2I
QN = 1e1I

# Initial guess
u = zeros(1, N - 1)
Δu = ones(1, N - 1)
x = simulate_dlti(u, A, B, x1)
λ = zeros(size(x, 1), N)

# Line search parameters
α = 1.0 # Step size
b = 1e-2 # Tolerance
α_min = 1e-16 # Minimum step size
loop = 0
max_iterations = 20

# Verbose
verbose = false

while maximum(abs, Δu) &gt; 1e-2 &amp;&amp; α &gt; α_min &amp;&amp; loop &lt; max_iterations
    verbose ? println(&quot;Iteration: &quot;, loop) : nothing

    # Backward pass to compute λ and Δu
    λ[:, N] .= QN * x[:, N]
    for n = N-1:-1:1
        Δu[:, n] .= - R\B&#39; * λ[:, n+1] - u[:, n]
        λ[:, n] .= Q * x[:, n] + A&#39; * λ[:, n+1]
    end

    # Forward pass (with line search) to compute x
    global α = 1.0
    b = 1e-2 # Tolerance
    unew = u + α .* Δu
    xnew = simulate_dlti(unew, A, B, x1)

    while J(xnew, unew) &gt; J(x, u) - b * α * norm(Δu)^2
        α = 0.5 * α
        unew = u + α .* Δu
        xnew = simulate_dlti(unew, A, B, x1)

        if verbose &amp;&amp; α &lt; α_min
            println(&quot;\tLine search failed to find a suitable step size&quot;)
            break
        end
    end

    u .= unew
    x .= xnew #added this dot so that global x is modified (https://discourse.julialang.org/t/local-and-global-variables-with-the-same-name-error-undefvarerror-x-not-defined/53951)
    verbose ? println(&quot;\tα = &quot;, α) : nothing

    global loop = loop + 1
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr33"><span class="sgr1">┌ Warning: </span></span>Assignment to `b` in soft scope is ambiguous because a global variable by the same name exists: `b` will be treated as a new local. Disambiguate by using `local b` to suppress this warning or `global b` to assign to the existing global variable.
<span class="sgr33"><span class="sgr1">└ </span></span><span class="sgr90">@ 7_trajectory_optimization.md:358</span></code></pre><pre><code class="language-julia hljs">series(simulate_dlti(u, A, B, x1))</code></pre><img src="218a463d.png" alt="Example block output"/><pre><code class="language-julia hljs">stairs(u[1, :])</code></pre><img src="ff15b2c5.png" alt="Example block output"/><p><strong>Exercise: Neural ODEs</strong></p><ul><li>Check out this <a href="https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode/">SciML note</a>. Can we connect what we learned about Pontryagin to this work?</li></ul><h3 id="Direct-optimal-control"><a class="docs-heading-anchor" href="#Direct-optimal-control">Direct optimal control</a><a id="Direct-optimal-control-1"></a><a class="docs-heading-anchor-permalink" href="#Direct-optimal-control" title="Permalink"></a></h3><p><strong>Tagline</strong></p><p>&quot;discretize, then optimize&quot;</p><p><strong>Ideas</strong></p><ul><li>Package the optimization variables into a trajectory</li><li>Set up a quadratic program defined over the trajectory</li><li>Observe the presence of sparsity</li></ul><p class="math-container">\[\begin{align}
\min_{x_{1:N}, u_{1:{N{-}1}}} &amp;\quad J(x_{1:N}, u_{1:{N{-}1}}) = \sum_{n=1}^{N-1} \tfrac{1}{2} x_n^T Q_n x_n + \tfrac{1}{2} u_n^T R_n u_n + \tfrac{1}{2} x_N^T Q_N x_N \\
\text{s.t.} &amp;\quad x_{n+1} = A_n x_n + B_n u_n \\
&amp;\quad Q_n \succeq 0,\, R_n \succ 0
\end{align}\]</p><pre><code class="language-julia hljs">m = 0.1 # Mass
A_c, B_c = double_integrator(m)
h = 0.1  # Time step
A, B = sparse.(continuous_to_discrete(A_c, B_c, h))
x1 = [1.0; 1.0]  # Initial state

N = 100
x_dim = size(A, 2)
u_dim = size(B, 2)

Q = sparse(1e-4I(x_dim))
R = sparse(1e-2I(u_dim))
QN = sparse(1e2I(x_dim))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 SparseArrays.SparseMatrixCSC{Float64, Int64} with 2 stored entries:
 100.0     ⋅ 
    ⋅   100.0</code></pre><p>Define  <span>$\begin{align} Z &amp;= \begin{bmatrix}      x_1 &amp; x_2 &amp; \cdots &amp; x_N \\
    u_1 &amp; u_2 &amp; \cdots &amp; u_N  \end{bmatrix} \\
\Rightarrow \vec{Z} &amp;= \begin{bmatrix} x_1 \\ u_1 \\ x_2 \\ u_2 \\ \vdots \\ x_N \\ u_N \end{bmatrix} \end{align}$</span></p><p>and drop the first state (known) and last control (not used), <span>$z = \vec{Z}[\text{length}(x_1){:}\text{end}{-}\text{length}(u_N)]$</span></p><pre><code class="language-julia hljs">z_dim = (N-2) * (x_dim + u_dim) + u_dim + x_dim</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">297</code></pre><p>Write the cost function as <span>$J = \tfrac{1}{2} z^T H z$</span>, where <span>$H = \begin{bmatrix}         R_1 &amp; 0 &amp; 0 &amp; &amp; 0 \\
        0 &amp; Q_2 &amp; 0 &amp; \cdots &amp; 0 \\
        0 &amp; 0 &amp; R_2 &amp; &amp; 0 \\
        &amp; \vdots &amp; &amp; \ddots &amp; \vdots \\
        0 &amp; 0 &amp; 0 &amp; \cdots &amp; Q_N \\
    \end{bmatrix}$</span></p><pre><code class="language-julia hljs"># Recall our shorthand for kron
H = blockdiag(sparse(R), I(N-2) ⊗ blockdiag(sparse(Q), sparse(R)), sparse(QN))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">297×297 SparseArrays.SparseMatrixCSC{Float64, Int64} with 297 stored entries:
⎡⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⎦</code></pre><p>Write the dynamics constraint, <span>$Cz = d$</span>, where <span>$C = \begin{bmatrix}     B_1 &amp; -I &amp; 0 &amp; 0 &amp; &amp; 0 \\
    0 &amp; A_2 &amp; B_2 &amp; -I &amp; \cdots &amp; 0 \\
    \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; 0 \\
    0 &amp; 0 &amp; \cdots &amp; A_{N-1} &amp; B_{N-1} &amp; -I \end{bmatrix}, \qquad d = \begin{bmatrix}     -A_1 x_1 \\
    0 \\
    0 \\
    \vdots \\
    0 \end{bmatrix}$</span></p><pre><code class="language-julia hljs">C = I(N-1) ⊗ [B -I(x_dim)]
for k = 1:N-2
    C[(k * x_dim) .+ (1:x_dim), (k * (x_dim + u_dim) - x_dim) .+ (1:x_dim)] = A
end
C</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">198×297 SparseArrays.SparseMatrixCSC{Float64, Int64} with 690 stored entries:
⎡⠛⢦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠀⠈⠙⢦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠈⠙⢦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⢶⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠶⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠳⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠲⣤⡀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠳⣤⡀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠲⣤⡀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⎦</code></pre><pre><code class="language-julia hljs"># Check the structure of C
k = 6
(
    C[(k * x_dim) .+ (1:x_dim), (k * (x_dim + u_dim) - x_dim) .+ (1:(2x_dim + u_dim))]
    == [A B -I(x_dim)]
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><pre><code class="language-julia hljs">d = [-A * x1; zeros((N-2) * x_dim)];</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">198-element Vector{Float64}:
 -1.1
 -1.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  ⋮
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0
  0.0</code></pre><p>Putting it all together,  <span>$\begin{align}     \min_z &amp;\quad \tfrac{1}{2} z^T H z \\
    \text{s.t.}&amp;\quad C z = d \end{align}$</span></p><ul><li>Lagrangian:</li></ul><p class="math-container">\[L(z, \lambda) = \tfrac{1}{2} z^T H z + \lambda^T (C z - d)\]</p><ul><li>KKT conditions:</li></ul><p class="math-container">\[\begin{align}
    &amp; \nabla_z L = H z + C^T \lambda \overset{!}{=} 0 \\
    &amp; \nabla_\lambda L = Cz - d \overset{!}{=} 0 \\
\end{align}\]</p><ul><li>Matrix form:</li></ul><p class="math-container">\[\Rightarrow \begin{bmatrix} H &amp; C^T \\ C &amp; 0 \end{bmatrix} 
    \begin{bmatrix} z \\ \lambda \end{bmatrix} 
    = \begin{bmatrix} 0 \\ d \end{bmatrix}\]</p><ul><li>Quick check: How many iterations will this take to solve?</li></ul><pre><code class="language-julia hljs">P = [H C&#39;; C zeros(size(C, 1), size(C, 1))]

res_qp = P \ [zeros(z_dim); d]

# Extract the minimizer
z_minimizer = res_qp[1:z_dim]
u_minimizer = z_minimizer[1:x_dim + u_dim:end];</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">99-element Vector{Float64}:
 -0.25526724211741625
 -0.22151609383946136
 -0.1910990418733456
 -0.1637649977921076
 -0.13927451626825543
 -0.11740014001102642
 -0.09792657992806568
 -0.08065075505435546
 -0.06538171417559757
 -0.051940458672337986
  ⋮
 -0.00013339034369839073
 -0.0001425785228803702
 -0.00015260480385746703
 -0.0001637046927068341
 -0.00017610914426376446
 -0.00019004575590729015
 -0.00020573979739887867
 -0.0002234150642871416
 -0.00024329454086428334</code></pre><pre><code class="language-julia hljs">fig, ax = series(simulate_dlti(u_minimizer, A, B, x1), labels=[&quot;q&quot;, &quot;q̇&quot;])
axislegend(ax)
fig</code></pre><img src="438008de.png" alt="Example block output"/><pre><code class="language-julia hljs">stairs(u_minimizer)</code></pre><img src="3e99e3bc.png" alt="Example block output"/><ul><li>Quick check: What about the temporal structure?</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../6_grape_demos/">« GRAPE Demos</a><a class="docs-footer-nextpage" href="../8_nonlinear_trajectory_optimization/">Nonlinear Trajectory Optimization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Friday 18 July 2025 02:44">Friday 18 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
